Mining Software Archives introduction
Corporations invest more than 300 billion US dollars annually in software production. Although new people are constantly entering the fi eld, some of them aren’t suffi ciently trained and therefore aren’t prepared to draw on the experience others have accumulated. This creates a situation in which every problem is perceived as new and unique, even though there’s plenty of experience to learn from. Studying and collecting such experience is the goal of empirical software engineering, and its evidence fi nds its way into textbooks and magazines. Empirical studies tell us, for example, that the later a problem is discovered, the more effort it takes to fi x it, and that 80 percent of the defects come from 20 percent of the code. Such fi ndings have long been common knowledge, but the consequences are very unspecifi c. How do we know where the most effort is spent? How do we know where the defects are? Which properties of the software or its development contribute to effort and quality? And, most important, how do we know whether some empirical or textbook fi nding applies to the project at hand? To answer such questions, we need data—about the product, people, and process. However, collecting such data manually is expensive and can interfere with the development process and cost valuable developer time. If the data is collected from humans (for example, in surveys), there’s a risk of bias, which we must estimate and deal with. Interpreting the data (agai