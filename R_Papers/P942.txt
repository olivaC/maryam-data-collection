A family of generalized entropies and its application to software fault localization
Fault localization is the process of locating faulty lines of code in a buggy program. This paper presents a novel approach to automate fault localization by combining feature selection (a fundamental concept in machine learning) with mutual information (a fundamental concept in information theory). Specifically, we present a family of generalized entropies for computing generalized mutual information, which enables feature selection. The family generalizes well-known entropies, such as Shannon and Renyi entropies, and lays the foundation of a uniform entropy-based technique for fault localization. We perform an experimental evaluation of our approach using the Siemens suite of subject programs. Experimental results show that while using mutual information based on generalized entropies allows more accurate fault localization that traditional techniques, the specific entropies used do not have a significant impact on fault localization effectiveness.