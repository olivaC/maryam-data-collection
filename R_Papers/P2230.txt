Incorporating Data Abstractions into Concurrency Control
Software applications are becoming increasingly harder to parallelize. Modern software systems written in imperative languages like Java and C# typically manipulate complex heap data structures, consist of multiple layers of abstraction, and have input- and deployment-specific behaviors that affect their available parallelism. This creates a significant challenge for parallelizing compilers, whose target transformations are normally conditioned on the assumption that the instructions designated for parallel execution access disjoint memory regions. Establishing this precondition over real-world applications is hard: Often there are dependencies between the candidate code blocks at the concrete level, at least over some of the inputs, and even if disjointness holds universally, it is hard for an automated verifier to formulate a proof to this effect. These limitations of dependence analysis in dealing with the complexity of modern programs, as well as their dynamic behavior, have shifted attention to runtime optimistic parallelization techniques, and most notably, software transactional memory (STM). The challenge with this approach is that STM typically incurs high overhead—due mainly to runtime tracking of memory accesses and conservative conflict detection—which often obviates the performance gain from parallelization. In this thesis, we take a step toward overcoming the limitations of these general parallelization techniques by taking benefit of user-provided data abstractions. These let us lift disjointness-driven parallelization to the level of semantic reasoning about data access and manipulation, enabling in turn nontrivial optimizations to the parallelization system. Specifically, we develop methods for abstract-level dynamic data dependence analysis, which serves us as the basis for specialized optimizations targeting prevalent program behaviors and common input profiles. We demonstrate the utility of our techniques with reference to realistic programs and popular parallelization techniques, e.g., by dramatically reducing the overhead of STM conflict detection