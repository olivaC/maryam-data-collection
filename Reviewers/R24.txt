Machine learning to facilitate incremental static program analysis
Techniques for facilitating incremental static program analysis based on machine learning techniques are provided. In one example, a system comprises a feature component that, in response to an update to a computer program, generates feature vector data representing the update, wherein the feature vector data comprises feature data representing a feature of the update derived from an abstract state of the computer program, and wherein the abstract state is based on a mathematical model of the computer program that is generated in response to static program analysis of the computer program. The system can further comprise a machine learning component that employs a classifier algorithm to identify an affected portion of the mathematical model that is affected by the update. The system can further comprise an incremental analysis component that incrementally applies the static program analysis to the computer program based on the affected portion
Identifying stored security vulnerabilities in computer software applications
Identifying stored security vulnerabilities in computer software applications by providing via a first interface of a computer software application during execution of the computer software application, test data having a characteristic of a malicious payload, where an interaction performed with the first interface resulted in data being written to a location within a persistent data store, and where an interaction performed with a second interface of the computer software application resulted in data being read from the location within the persistent data store, and identifying a stored security vulnerability associated with the computer software application if the test data are written to the persistent data store at the location.
Automatic Generation of Precise and Useful Commutativity Conditions (Extended Version)
Reasoning about commutativity between data-structure operations is an important problem with applications including parallelizing compilers, optimistic parallelization and, more recently, Ethereum smart contracts. There have been research results on automatic generation of commutativity conditions, yet we are unaware of any fully automated technique to generate conditions that are both sound and effective. We have designed such a technique, driven by an algorithm that iteratively refines a conservative approximation of the commutativity (and non-commutativity) condition for a pair of methods into an increasingly precise version. The algorithm terminates if/when the entire state space has been considered, and can be aborted at any time to obtain a partial yet sound commutativity condition. We have generalized our work to left-/right-movers and proved relative completeness. We describe aspects of our technique that lead to useful commutativity conditions, including how predicates are selected during refinement and heuristics that impact the output shape of the condition. We have implemented our technique in a prototype open-source tool Servois. Our algorithm produces quantifier-free queries that are dispatched to a back-end SMT solver. We evaluate Servois through two case studies: (i) We synthesize commutativity conditions for a range of data structures including Set, HashTable, Accumulator, Counter, and Stack. (ii) We consider an Ethereum smart contract called BlockKing, and show that Servois can detect serious concurrency-related vulnerabilities and guide developers to construct robust and efficient implementations.
Synthesis of security exploits via self-amplifying deep learning
Techniques for synthesizing security exploits via self-amplifying deep learning are provided. In one example, a computer-implemented method can comprise generating, by a system operatively coupled to a processor, a probabilistic model based on an evaluation of one or more first payloads included in a first group of payloads. The computer implemented method can also comprise determining, by the system, based on the probabilistic model, that at least one first payload from the first group of payloads is invalid. Additionally, the computer implemented method can comprise, generating, by the system, a second group of payloads based on removing the at least one invalid first payload from the first group of payloads
Visually configurable privacy enforcement
A method is disclosed including presenting via a graphical user interface of an application at least one element that is activatable to specify a source of information as a source of information to be logged, receiving from the user via the graphical user interface an activation of the at least one element, and in response to receiving the activation of the at least one element, instrumenting the application to capture and log information received from the specified source of information, capturing information received by the application from the specified source using the instrumentation, logging the information in memory, capturing data that is output by the application, comparing the captured data to the logged information, determining based on the comparison that a leak of the information has occurred, and in response to determining that a leak of the information has occurred, performing a corrective action.
Finding services in a service registry system of a service-oriented architecture
Searching a service registry system including a plurality of services identified by respective service names, wherein at least some of said service names being associated with a set of client identifiers, includes receiving a search request, said request including a service name and a further set of client identifiers, searching, using a processor, the service registry system for a match between the requested service name and a service name of one of said services in the service registry system, and, in the absence of such a match, searching, using the processor, the service registry system for services that have an association with at least some of the client identifiers in said further set. A search result can be returned.
Warning filter based on machine learning
Techniques for generating a warning filter to filter the warnings output from a static program analysis tool are provided. In one example, a computer-implemented method comprises determining feature vector data for a set of warnings, wherein the set of warnings is generated in response to static analysis of a computer program, and wherein the feature vector data comprises a feature vector indicative of an attribute of a warning of the set of warnings. The computer-implemented method also comprises determining a warning filter that identifies a first subset of the set of warnings as representing true positives based on the feature vector data and classified warning data, and wherein the classified warning data represents a second subset of the set of warnings that have been classified to indicate whether respective members of the second subset are indicative of true positives.
Detecting race condition vulnerabilities in computer software applications
Testing computer software applications is performed by identifying first and second executable portions of the computer software application, where the portions are configured to access a data resource, and where at least one of the portions is configured to write to the data resource, instrumenting the computer software application by inserting one or more instrumentation instructions into one or both of the portions, where the instrumentation instruction is configured to cause execution of the portion being instrumented to be extended by a randomly-determined amount of time, and testing the computer software application in multiple iterations, where the computer software application is executed in multiple parallel execution threads, where the portions are independently executed at least partially in parallel in different threads, and where the computer software application is differently instrumented in each of the iterations.
Application integrity verification in multi-tier architectures
A method and system of determining a vulnerability of software are provided. In a setup phase, an authorized application is received from an authorized source. Static analysis is performed to identify a plurality of structural characteristics, which are stored. During an active phase, a call is received from a user device having a target application purporting to be a version of the authorized application, during a runtime of the target application. One or more structural characteristics are selected from the plurality of structural characteristics. The user device is requested to provide the selected one or more structural characteristics from the target application. Upon determining that the report does not provide a match between the selected one or more structural characteristic of the authorized application and the target application, the version of the target application is identified to be unsecure.
Install-Time Security Analysis of Mobile Applications
Online security analysis is provided by installing an analysis agent on a mobile device. The analysis agent monitors the mobile device to detect an initiation of installation for a new application that is to be installed on the mobile device. In response to the initiation of installation, the analysis agent quarantines a set of resources corresponding to the new application; analyzes the set of resources to determine whether or not at least one of a potential security threat or a security misconfiguration exists; and, in response to determining that at least one of the potential security threat or the security misconfiguration exists, generates an alert for informing a user that the potential security threat or the security misconfiguration exists.
Crowd based detection of device compromise in enterprise setting
A computer-implemented method, computer program product, and system for detecting anomalous behavior of computing devices are provided. The computer-implemented method for detecting anomalous behavior of computing devices may include establishing a network of computing devices; receiving shared data from the networked devices; determining device behavior; predicting future device behavior, detecting anomalous device behavior, and sending an alert in response to a detection of anomalous device behavior.
Comparison between different descriptions of a web service
In one embodiment, a computer-implemented method for comparing first and second descriptions of a web service includes computing a distance between each type used as a parameter in the first description and each type used as a parameter in the second description. A distance is calculated between methods in each of two or more pairs of methods. Each pair includes a method in the first description and a method in the second description. The calculating is performed by comparing the parameters of the first set of methods and the second set of methods using the computed distances between types. To the calculated distance between each pair of methods is added the distance between the names of the compared methods and the distance between the returned types of the compared methods. For each method in the first description, the method in the second description with the lowest calculated distance is output.
System, method and apparatus for fine-grained privacy specification and verification
A method includes receiving from a user via a user interface an activation of at least one element to set a privacy policy specifying the maximum amount of confidential data that is authorized to be leaked to a sink, tracking movement of confidential data through an application, determining based on the tracked movement of the confidential data that the confidential data is leaked to the sink by the application, comparing the confidential data that is leaked to the sink to the specified maximum amount of confidential data that is authorized to be leaked to the sink, and presenting to the user via the user interface an indication of whether the application complies with the privacy policy set by the user based on the comparison.
System, method and apparatus for preventing vulnerable interleavings in web applications at compile time
Systems, methods, and computer program products are disclosed including receiving a computer program, compiling the computer program, performing data flow analysis on the computer program to identify accesses to data locations by execution units at compile-time, generating a list of data-flow paths including accesses to one or more of the data locations, determining that more than one of the execution units accesses the same data location based on the list of data-flow paths, determining the existence of a potential vulnerability in at least one of the data-flow paths based at least in part on the determination that more than one of the execution units accesses the same data location, synthesizing a scheduling constraint for the data location based at least in part on the determination of the existence of the potential vulnerability in the at least one of the data-flow paths, and implementing the scheduling constraint for the data location
System, method, and apparatus for crowd-sourced gathering of application execution events for automatic application testing and replay
A method is disclosed including instrumenting a first version of an application on a plurality of end user devices and receiving execution data for the first version of the application from at least some of the plurality of end user devices. The execution data may be generated by the instrumentation in response to an execution of the first version of the application by the at least some of the end user devices. The method further includes automatically generating execution scripts based on the received execution data. The execution scripts may be configured to reproduce the execution of the first version of the application by the at least some of the end users devices. The method further includes automatically executing at least one of the execution scripts on an updated version of the application.
Semantic Privacy Enforcement
Providing an online defense mechanism against privacy threats by storing a database of facts and an abstractions database in a storage medium. The database of facts includes a plurality of private data fields comprising at least a first set of private data fields and a second set of private data fields. The abstractions database associates at least one respective field of the first set of private data fields with at least one corresponding field of the second set of private data fields. A request is received from a mobile application for a first private data value from the first set of private data fields. The abstractions database and the database of facts are used to identify a second private data value from the second set of data fields that is associated with the first private data value. A response is formulated for the request by providing the second private data value.
Cross-platform program analysis using machine learning based on universal features
A method for performing program analysis includes receiving programs of a first platform that have been assigned a first label and programs of the first platform that have been assigned a second label. Each of the programs of the first platform is expressed as platform-independent logical features. A discriminatory model or classifier is trained, using machine learning, based on the expression of the programs of the first platform as platform-independent logical features, to distinguish between programs of the first label and programs of the second label. An unlabeled program of a second platform is received and is expressed as platform-independent logical features. The trained discriminatory model or classifier is used to determine if the unlabeled program warrants the first label or the second label, based on the expression of the unlabeled program as platform-independent logical features
Root cause analysis in dynamic software testing via probabilistic modeling
Techniques for performing root cause analysis in dynamic software testing via probabilistic modeling are provided. In one example, a computer-implemented method comprises initializing, by a system operatively coupled to a processor, a threshold value, a defined probability value, and a counter value. The computer-implemented method also includes, in response to determining, by the system, that a probability value assigned to a candidate payload of one or more candidate payloads exceeds the defined probability value, and in response to determining, by the system, that the counter value exceeds the threshold value: determining, by the system, that a match exists between the candidate payload and an input point based on an application of the candidate payload to the input point resulting in a defined condition, wherein the one or more candidate payloads are represented by population data accessed by the system.
Cross-platform program analysis using machines learning based on universal features
A method for performing program analysis includes receiving programs of a first platform that have been assigned a first label and programs of the first platform that have been assigned a second label. Each of the programs of the first platform is expressed as platform-independent logical features. A discriminatory model or classifier is trained, using machine learning, based on the expression of the programs of the first platform as platform-independent logical features, to distinguish between programs of the first label and programs of the second label. An unlabeled program of a second platform is received and is expressed as platform-independent logical features. The trained discriminatory model or classifier is used to determine if the unlabeled program warrants the first label or the second label, based on the expression of the unlabeled program as platform-independent logical features.
Application modification based on a security vulnerability
In some examples, a method includes inserting monitoring instructions to be executed with a set of conditional operations and data type operations in an application and executing the application with a benign value. The method can also include storing at least one of result values and path constraints from the monitoring instructions, the result values comprising values generated by each conditional operation and each data type operation executed with the benign value. Furthermore, the method can include generating a prohibited value corresponding to a security vulnerability that satisfies the set of conditional operations and data type operations in the application based on the result values and the path constraints and modifying the application to prevent execution of the prohibited value.
System, method and apparatus for extracting usage-based fine grained permissions
A fine grained permission method and system that parameterizes permissions based on an objective criterion. The method includes accessing libraries of application programs requiring a permission, automatically extracting types of the parameters and respective corresponding fields read by the libraries requiring the permission, filtering the extracted types of parameters and fields based on a usage criteria to determine a filtered type of parameter and field for the permission and storing the filtered type parameter and field for the permission in a database. A request for a permission is passed to a fine grained permission module which obtains the filtered type of parameter and field for the permission, determines a specific parameter for the permission based on the filtered type of parameter and field and parameterizes the permission using the specific parameter. Downloading of the application program is completed by limiting the permission based on the specific parameter.
Detecting vulnerable applications
A method and system of determining a vulnerability of software. Libraries are downloaded and stored in a database. For each library, a set of features are extracted and stored in a library index table of the database. For each library, it is determined whether it poses a security concern and flagged accordingly in the library index table. Applications are downloaded and stored in the database. For each application a set of features are extracted and stored in an application index table of the database. For each application, the set of features of the application of the application are compared to the set of features of each of the libraries in the library index table to identify which libraries in the library index table are associated with the application. For each application, a name of the application and names of the associated libraries are stored in a vulnerability reference table in the database.
System, method and apparatus for sensor virtualization in mobile devices
A method and system for virtualizing mobile device sensors includes requesting from a first mobile device a virtual connection with a mobile device having a specific type of sensor, receiving a response from a second mobile device having the sensor, establishing a trusted temporary communication connection between the first and second mobile devices, sending a control signal from an application program on the first mobile device to the second mobile for operating the sensor on the second mobile device and receiving device sensor data from the sensor on the second mobile device. The operating system of the first mobile device is coupled with the application program by a virtual machine monitor running on the first mobile device such that the first mobile device is a host machine and the second mobile device is a guest machine.
Privacy detection of a mobile application program
Privacy violation detection of a mobile application program is disclosed. Regular histories of the mobile application are mined. A call-graph representation of the mobile application program can be created and sequences of events of interest according to the platform specification of the mobile application can be collected. A plurality of learnable features are extracted from the regular histories. The plurality of learnable features are combined into a single feature vector which is fed into a machine-learning-based classification algorithm. Whether the mobile application program includes one or more permissions for accessing unauthorized privacy data of a mobile application user is determined based on a machine learning classification of the single feature vector. The collected sequences can be reduced into a plurality of feature vectors which can include at least one of a happens-before feature and a multiplicity of occurrences feature.
System, method and apparatus for ad-hoc utilization of available resources across mobile devices
A method of collaboratively executing a task using first to N-th mobile devices in an ad-hoc network includes determining collaborative mobile devices out of the second to N-th mobile devices, receiving information corresponding to the collaborative mobile devices, dividing the task into first to M-th sub tasks, assigning each of the first to M-th sub tasks to at least one of the collaborative mobile devices, requesting executions of the first to M-th sub tasks to the collaborative mobile devices, and receiving execution results of the first to M-th sub tasks from the collaborative mobile devices. M and N are integers greater than one.
Identifying and isolating library code in software applications
A computer system, method, and computer readable product are provided for identifying and isolating library code that has been obfuscated in software applications. A call graph is created for the execution of at least one module of preexisting library code within a bundle of software modules through either static analysis of the software code or dynamic analysis of the executing code, and then one or more anchor points are devised based upon the call graph that are indicative of the preexisting library code. Then a bundle of software modules can be analyzed or its execution monitored to determine if a discrete module of library code is present in the executing bundle based upon the modules' interaction with the one or more anchor points, and the discrete module of library code in the executing bundle can be identified as a module of preexisting library code.
UTILIZING LIKELY INVARIANTS FOR RUNTIME PROTECTION OF WEB SERVICES
An exemplary method for use with an application includes: testing the application with a set of security payloads to produce a set of execution traces, wherein testing the application with a given one of the set of security payloads produces a corresponding one of the set of execution traces; determining a set of candidate points comprising at least one candidate point for each of the set of security payloads, wherein a candidate point for the given one of the set of security payloads is determined based on the corresponding one of the set of execution traces; inferring a set of trust boundaries based on the determined set of candidate points; computing one or more possible transition points across the inferred set of trust boundaries; and instrumenting the application with a security defense at each of the computed possible transition points across the inferred set of trust boundaries.
System and method for bypassing evasion tests with applications in analysis and monitoring of mobile applications
A given program is said to be evasive when it performs different behaviors under different running conditions. In general, the aim of evasion is to make the analysis, monitoring or reverse engineering of the given software system harder for an analyzer. Evasion is largely used by malware to increase its effectiveness. Aspects of the invention include a system, method and computer program product to detect and bypass evasion mechanisms for software analysis. Given a set of fingerprinting sources and a program, we first search for evasion candidates. These are program slices where the data depending on fingerprinting sources is used at branching point. In a second step, instrumentation strategies are applied to generate programs where the combination of possible branches is forced via toggling of return values and/or expression values. Finally, the resulting programs are each executed dynamically to monitor deltas between observed behaviors across the original and instrumented versions.
SYSTEM, METHOD AND APPARATUS FOR DERIVING ROOT CAUSE FOR SOFTWARE TEST FAILURE
For a program of interest represented as a sequence of states comprising variables and flags wherein controls transition the program from state to state, and wherein the program includes tests at prescribed locations in the program that are applied upon specific states and generate observables, a method includes inserting at different points in the program hooks that capture program runtime behaviors constituting classification features. The method further includes flattening the program states, commands and tests along a program run-time timeline, and identifying a root cause of a program failure by backtrack analyzing a stream of input states and commands and output consequent states, commands and test results to detect causal correlations between variables, states and commands. The step of backtrack analyzing includes determining joint conditional probabilities and identifying candidate failure root causes that maximize conditional probabilities.
Eliminating redundant interactions when testing computer software applications
Testing computer software applications includes comparing multiple execution paths associated with multiple interactions performed with a computer software application during execution of the computer software application in order to determine which of the execution paths are similar in accordance with a predefined similarity criterion, identifying a subset of the interactions whose associated execution paths are similar in accordance with the predefined similarity criterion, and performing fewer than all of the interactions in the subset with the computer software application during execution of the computer software application.
Using natural language processing for detection of intended or unexpected application behavior
Detection of unintended application behaviors, where natural language processing (NLP) techniques are used to analyze the application, and specifically its graphical user interface (GUI), and construct an acceptable (or expected) list per-context actions. Actions executed by the application in a given context that do not fall within the list are flagged as unexpected (or anomalous).
Automatic correction of cryptographic application program interfaces
A computer system may identify a cryptographic application programming interface (API) call for a program. The cryptographic API call may include a first variable. The computer system may determine that the first variable is a static value. The computer system may tag the first variable. The computer system may determine that the cryptographic API call will be executed. The computer system may replace the first variable with a second variable during execution of the program. The computer system may execute the cryptographic API call with the second variable.
Foraging goes mobile: Foraging while debugging on mobile devices
Although Information Foraging Theory (IFT) research for desktop environments has provided important insights into numerous information foraging tasks, we have been unable to locate IFT research for mobile environments. Despite the limits of mobile platforms, mobile apps are increasingly serving functions that were once exclusively the territory of desktops - and as the complexity of mobile apps increases, so does the need for foraging. In this paper we investigate, through a theory-based, dual replication study, whether and how foraging results from a desktop IDE generalize to a functionally similar mobile IDE. Our results show ways prior foraging research results from desktop IDEs generalize to mobile IDEs and ways they do not, and point to challenging open research questions for foraging on mobile environments.
Security analysis using relational abstraction of data structures
Analyzing program code can include detecting an instance of a container within the program code using a processor, selecting a model container correlated with the container using the processor, and creating an instance of the model container within memory using the processor. A data-flow of the program code can be tracked through the instance of the model container instead of the instance of the container.
Precision-tuned runtime monitoring
Preliminary program analysis of an executable may be performed. A security vulnerability level of a portion of the executable may be determined based on the preliminary program analysis. The security vulnerability level of the portion may be compared to a security vulnerability threshold. The precision of runtime monitoring of the portion may be tuned based on the comparison.
Measuring robustness of web services to denial of service attacks
A method for measuring robustness of web services includes selecting a web-service method for testing. The request pattern with the slowest response by the web-service method from a series of request patterns is selected as a request pattern for testing. The series of request patterns includes irregular requests, each having a payload aimed at destabilizing the web service. A test is applied to the web-service method, using the selected request pattern applied at an increasing frequency to the web-service method. The response time of the request pattern is monitored by the web-service method. The frequency of the applied request pattern when a threshold maximum time for response of the web-service method to the request pattern is reached, or when the method fails, is determined by a computer processor. A metric is determined for the web-service method based on the frequency of the applied request pattern required to reach the threshold.
Reporting security vulnerability warnings
A computer-implemented method, computer program product, and computing system is provided for reporting security vulnerabilities. In an embodiment, a method may include receiving a set of potential security vulnerabilities associated with a program. The method may also include filtering the set of potential security vulnerabilities by eliminating one or more spurious security vulnerabilities to generate a set of likely security vulnerabilities. The method may further include consolidating the set of likely security vulnerabilities into one or more solution categories, each of the one or more solutions categories defining a solution for remedying each of the likely security vulnerabilities within the solution category.
Simulating black box test results using information from white box testing
Systems, methods are program products for simulating black box test results using information obtained from white box testing, including analyzing computer software (e.g., an application) to identify a potential vulnerability within the computer software application and a plurality of milestones associated with the potential vulnerability, where each of the milestones indicates a location within the computer software application, tracing a path from a first one of the milestones to an entry point into the computer software application, identifying an input to the entry point that would result in a control flow from the entry point and through each of the milestones, describing the potential vulnerability in a description indicating the entry point and the input, and presenting the description via a computer-controlled output medium.
Detection of software or hardware incompatibilities in software packages
In an approach for determining compatibility between a computing device and a software application, a processor receives code of a software application. A processor generates a call graph for the software application using the code, wherein the call graph describes at least a first type of hardware component required to execute the software application. A processor identifies a set of one or more hardware components included within a computing device. A processor determines whether the computing device is compatible with the software application based on, at least, the call graph and the determined set of one or more hardware components included within the computing device.
Execution of test inputs with applications in computer security assessment
A given application is instrumented to trace its execution flow. Constraints and/or transformation associated with input identified in the execution flow are mirrored on a set of candidate test payloads. The set of candidate test payloads are modified or pruned based on the execution flow of the instrumented application reaching a security operation with the input satisfying the constraints while the payloads may not. If the set of candidate test payloads is not empty at reaching the security operation, it is determined that the give application has vulnerability and a signal issuing a warning may be generated and transmitted.
Protecting an application via an intra-application firewall
One or more communication interfaces of a first application may be scanned. In response to the scanning, it may be determined that at least a first component of the first application is subject to public access from any application. One or more public access features associated with the first component may be removed, wherein the first component is no longer subject to public access from any application. A first module may be added to the first application to control access to data to or from the first component via one or more security rules.
Solution-centric reporting of security warnings
A new paradigm for security analysis is provided by transitioning code analysis reporting from the problem space (the warnings themselves), to a solution space (potential solutions to the identified problems). Thus, instead of reporting raw findings to the user, the automated system as described here outputs proposed solutions to eliminate the defects identified in the security analysis. A consequence of this approach is that the report generated by the analysis tool is much more consumable, and thus much more actionable. Preferably, the report provides the user with one or more candidate location(s) at which to apply a fix to an identified security problem. These locations preferably are identified by processing overlapping nodes to identify one or more solution groupings that represent an API for a sanitization fix. The report also includes one or more recommendations for the fix, and preferably the report is generated on a per-vulnerability type basis.
Customizing a security report using static analysis
A control graph representing a model of data flow of a computer program can be generated during a static analysis. Respective edge weights can be assigned to edges of a plurality of paths in the control flow graph. A size of the uniform-cost search method can be dynmically configured based on a size of the control flow graph. A total edge weight for the considered paths can be determined based the edge weights assigned to the respective edges of the considered path. At least one path of the considered paths in the control flow graph whose total edge weight satisfies a particular total edge weight criteria can be identified. The control flow graph can be updated to indicate to a user the at least one path in the control flow graph whose total edge weight satisfies the particular total edge weight criteria.
Determining privacy leaks
Techniques for determining privacy leaks are described herein. The techniques may include (i) providing private data as input for an application, wherein the private data includes a signature identifying the private data; (ii) monitoring an output of the application for a presence of the signature; and (iii) determining that a private data leak has occurred in the application, wherein the determining is based, at least in part, on the presence of the signature in the output.
Application Modification
Techniques for modifying an application are described herein. In some examples, a method includes generating, via a processor, a representation of an application and detecting a flow of data in the representation of the application based on static analysis. The method can also include detecting a predetermined property to be verified, the predetermined property comprising a source point in the representation of the application and a sink point in the representation of the application. In addition, the method can include detecting that the flow of data violates the predetermined property. Furthermore, the method can include selecting a set of changes to the representation of the application that prevents the violation of the predetermined property and modifying the application based on the selected set of changes
Testing application internal modules with instrumentation
Testing internal modules of application code includes applying, via a computer processor, instrumentation hooks to internal module interface points and external module interface points of the application code, executing the application code and recording values received at the instrumented interface points, determining an accessible internal module input point and a constraint based on the recorded values from the instrumented external module interface points, and testing the accessible internal module input point based on the constraint.
Generating collapsed user interface interaction sequence controls in mobile applications
Generating a set of single collapsed user interface interaction sequence controls for an application is provided. A single collapsed user interface interaction control is generated for one or more identified user interface interaction sequences that are collapsible within the application. A customized version of the application is generated for a plurality of users associated with a plurality of registered client devices by inserting each generated single collapsed user interface interaction sequence control into the application.
Testing web applications for security vulnerabilities with metarequests
A method includes instantiating, in response to a request by an executing application, an input data object with one or more uninitialized fields and traversing a path toward a sink in the executing application to a branching point of the executing application. In response to reaching the branching point, one or more parameters are provided for some or all of the one or more uninitialized fields of the input data object, wherein the one or more parameters were determined prior to beginning of execution of the executing application to cause a branch to be taken by the executing application toward the sink. The path is traversed toward the sink at least by following the branch in the executing application. Apparatus and computer program products are also disclosed.
System, method and apparatus for fully precise hybrid security verification of mobile applications
A security verification system and method that includes outputting a list of potential dataflow vulnerabilities as a first output from inputting a subject program and security specification, mapping candidate vulnerabilities to a user interface (UI) entry point and payload from the output of the list of potential dataflow vulnerabilities to provide a second output, and performing directed testing of the second output.
Modifying Evasive Code Using Correlation Analysis
An example computer-implemented method includes receiving, via a processor, an application to be tested, a set of intrusive monitoring capabilities, and a set of external monitoring capabilities. The method includes executing, via the processor, the application in a clean environment to generate unmonitored application behavior. The method includes executing, via the processor, the application with intrusive monitoring based on two randomly generated seeds to generate trigger events and external monitoring to detect changes of application behavior in response to the intrusive monitoring. The method includes computing, via the processor, a correlation measure between the trigger events and the detected changes in the application behavior. The method includes modifying, via the processor, the application in response to detecting the application is evasive based on the correlation measure.
Synthesizing inputs to preserve functionality
A computer implemented method of preserving functionality in a computer program by generating customized mock inputs may include identifying a set of functionalities of the computer program, where a first functionality has a first input, and a second functionality has a second input. The method may also include determining a first and a second constraint respectively on the first and second inputs, where the first constraint defines a set of values of the first input which enables the first functionality, and the second constraint defines a set of values of the second input which enables the second functionality. The method may then include generating a constraint satisfaction problem including the first and second constraints, and determining whether a tuple of mock input values exists that satisfy the constraint satisfaction problem. The method may additionally include providing the tuple to the computer program as the customized mock inputs.
Security analysis using relational abstraction of data structures
Analyzing program code can include detecting an instance of a container within the program code using a processor, selecting a model container correlated with the container using the processor, and creating an instance of the model container within memory using the processor. A data-flow of the program code can be tracked through the instance of the model container instead of the instance of the container.
Detecting malicious code based on conditional branch asymmetry
A computer-implemented method for detecting malware based on asymmetry includes receiving, via a processor, an application to be tested. The method includes computing, via the processor, a static call graph for the application. The method also includes generating, via the processor, an interprocedural control-flow graph (ICFG) based on the static call graph. The method further includes detecting, via the processor, symbolic path conditions and executable operations along different paths of conditional branches in the ICFG. The method further includes detecting, via the processor, asymmetries based on the symbolic path conditions and the executable operations. The method includes detecting, via the processor, a malicious block based on the detected asymmetries. The method further includes modifying, via the processor, the application based on the detected malicious block
Self-repair and distributed-repair of applications
A method is provided to instrument applications with an instrumentation policy that is visually configurable and allows for run-time modifications of the policy. Instrumentation is achieved without modifying the source code of the applications. Modification of the instrumentation policy of an application is applied without re-compiling, re-deploying, and re-provisioning the application. The instrumentation tracks the flow of values at run time throughout the execution of an application and fixes any security violation automatically by dynamically modifying any value that violates integrity or confidentiality.
Building coverage metrics and testing strategies for mobile testing via view enumeration
A method and method for testing an application includes performing a static analysis of metadata of coding of an application, using a test application program executed by a processor on a computer. Available user interface states are simulated based on the static analysis. A configuration file of the application is accessed and parsed to enumerate states possible for the application. A coverage metric is calculated for the application based on a number of states reached by the simulating and a number of states possible.
Security enforcement in the presence of dynamic code loading
A method (and structure) for enforcing a security policy includes retrieving from a memory a program to be verified against a security policy and a security specification defining the security policy. A static program analysis is performed on the program, using a processor on a computer, to determine whether the program is compatible with the security specification. The program is rejected if the program is determined by the static program analysis as being incompatible with the security specification. If the program is determined during the static program analysis as compatible with the security specification under static analysis criteria, then building a call-graph representation of the program for use to evaluate any dynamically-loaded code during an execution of the program. Any paths, if any, of the call-graph representation that reach at least one policy-relevant operation is marked.
Trace recovery via statistical reasoning
A method (and system) for trace recovery includes retrieving a code listing from a memory and performing a static analysis on the retrieved code listing. Based on the static analysis, profiling instructions are inserted in the code.
System and method for discovering ad-hoc communities over large-scale implicit networks by wave relaxation
A method includes computing a diffusion vector starting with a seed, querying nodes for connections, reweighting diffusion vector based on the degrees, sorting nodes based upon magnitude in the reweighted diffusion vector which is obtained through wave relaxation solution of a time-dependent initial value problem, detecting a community through a sweep over the nodes according to their rank, and selecting a prefix that minimizes or maximizes an objective function.
System, method and apparatus for usable code-level statistical analysis with applications in malware detection
A method, including identifying over a set of classified applications a set of discriminating features, determining via code analysis, when a first application is subjected to classification, positions of the first application's code that correspond to discriminating features, and forwarding to a classification algorithm, such that according to its output the code fragments corresponding to the discriminating features are reported beyond a determination itself of the discriminating features
Z3str2: an efficient solver for strings, regular expressions, and length constraints
In recent years, string solvers have become an essential component in many formal verification, security analysis, and bug-finding tools. Such solvers typically support a theory of string equations, the length function, and the regular-expression membership predicate. These enable considerable expressive power, which comes at the cost of slow solving time, and in some cases even non-termination. We present three techniques, designed for word-based SMT string solvers, to mitigate these problems: (1) detecting overlapping variables, which is essential to avoiding common cases of non-termination; (2) pruning of the search space via bi-directional integration between the string and integer theories, enabling new cross-domain heuristics; and (3) a binary search based heuristic, allowing the procedure to skip unnecessary string length queries and converge on consistent length assignments faster for large strings. We have implemented above techniques atop the Z3-str solver, resulting in a significantly more robust and efficient solver, dubbed Z3str2, for the quantifier-free theory of string equations, the regular-expression membership predicate, and linear arithmetic over the length function. We report on a series of experiments over four sets of challenging real-world benchmarks, where we compare Z3str2 with five different string solvers: S3, CVC4, Kaluza, PISA and Stranger. Each of these tools utilizes a different solving strategy and/or string representation (based e.g. on words, bit vectors or automata). The results point to the efficacy of our proposed techniques, which yield dramatic performance improvement. We also demonstrate performance improvements enabled by Z3str2 in the context of symbolic execution for string-manipulating programs. We observe that the techniques presented here are of broad applicability, and can be integrated into other string solvers to improve their performance.
Identifying Android library dependencies in the presence of code obfuscation and minimization
The fast growth of the Android app market motivates the need for tools and techniques to analyze and improve Android apps. A basic capability in this context is to identify the libraries present in a given Android app, including their exact version. The problem of identifying library dependencies is made difficult by two common build-time transformations, namely code minimization and obfuscation. Minimization typically incorporates used library fragments into an app, while obfuscation renames symbols globally across an app. In this paper, we tackle both of these challenges via a unified approach, which abstracts app and library classes into summaries of their interactions with system libraries. The summarization technique is resistant to obfuscation, and is amenable to efficient similarity detection (matching). We lift the class-wise matches into a set of library dependencies by encoding this problem as a global constraint/optimization system across all app classes and available libraries. Our techniques identify the exact libraries and their versions used in the apps, for clear apps the recall is almost perfect at 98%. For obuscated/minimized apps it stands at 85%.
A solver for a theory of strings and bit-vectors
We present the Z3strBV solver for a many-sorted first-order quantifier-free theory Tw, bv of string equations, string length represented as bit-vectors, and bit-vector arithmetic aimed at formal verification, automated testing, and security analysis of C/C++ applications. Our key motivation for building such a solver is the observation that existing string solvers are not efficient at modeling the combined theory over strings and bit-vectors. We demonstrate experimentally that Z3strBV is significantly more efficient than a reduction of string/bit-vector constraints to strings/natural numbers followed by a solver for strings/natural numbers or modeling strings as bit-vectors. We also propose two optimizations. First, we explore the concept of library-aware SMT solving, which fixes summaries in the SMT solver for string library functions such as strlen in C/C++. Z3strBV is able to consume these functions directly instead of re-analyzing the functions from scratch each time. Second, we experiment with a binary search heuristic that accelerates convergence on a consistent assignment of string lengths. We also show that Z3strBV is able to detect nontrivial overflows in real-world system-level code, as confirmed against seven security vulnerabilities from the CVE and Mozilla databases.
Visual Configuration of Mobile Privacy Policies
Mobile applications often require access to private user information, such as the user or device ID, the location or the contact list. Usage of such data varies across different applications. A notable example is advertising. For contextual advertising, some applications release precise data, such as the users exact address, while other applications release only the users country. Another dimension is the user. Some users are more privacy demanding than others. Existing solutions for privacy enforcement are neither app- nor user- sensitive, instead performing general tracking of private data into release points like the Internet. The main contribution of this paper is in refining privacy enforcement by letting the user configure privacy preferences through a visual interface that captures the applications screens enriched with privacy-relevant information. We demonstrate the efficacy of our approach w.r.t. advertising and analytics, which are the main (third-party) consumers of private user information. We have implemented our approach for Android as the VisiDroid system. We demonstrate VisiDroids efficacy via both quantitative and qualitative experiments involving top-popular Google Play apps. Our experiments include objective metrics, such as the average number of configuration actions per app, as well as a user study to validate the usability of VisiDroid.
Identifying and tracking sensitive data
A method of classifying privacy relevance of an application programming interface (API) comprises analyzing a set of input applications to identify a plurality of custom APIs and generating a respective taint specification for each identified custom API. The method further comprises generating taint flows based on each taint specification and matching features and associated feature values from the taint flows to a set of feature templates. The method also comprises correlating the matched features and associated feature values with respective privacy relevance of the plurality of custom APIs to identify a set of privacy relevant features. The method further comprises detecting a candidate API, extracting features from the candidate API and comparing the extracted features to the set of privacy relevant features. Based on the comparison, a label is assigned to the candidate API indicating privacy relevance of the candidate API.
Detection of antipatterns through statistical analysis
A computer implemented method of detecting code antipatterns, comprising: 1) Receiving a code containing one or more of a plurality of code segments, each one of the one or more code segments includes one or more of a plurality of patterns. 2) Automatically analyzing each one of the one or more code segment to create an array of a plurality of features vectors, each one of the plurality of features vectors maps a plurality of predefined features found in one or more patterns. 3) Matching each one of the plurality of features vectors with a plurality of template features vectors each representing one of a plurality of antipatterns, the plurality of template features vectors is stored in an antipatterns dataset. 4) Determining a presence or an absence of each of the plurality of antipatterns within each of the one or more code segments according to the matching.
System, method and apparatus for simultaneous definition and enforcement of access-control and integrity policies
Access-control and information-flow integrity policies are enforced in a computing system by detecting security-sensitive sinks in software code for an application running on the computing system and retrieving an access-control policy from a database accessible to the computing system. The access-control policy maps a set of access permissions within the computing system to each one of a plurality of principals. For each detected security-sensitive sink, all principals that influence that security-sensitive sink are detected and an overall access permission is assigned to each security-sensitive sink by taking the intersection of the access permission sets for all influencing principals of that security-sensitive sink. If this permission set is inadequate, an integrity violation is reported. In addition, permission labels are assigned to each value of variables used in the security-sensitive sinks. Each permission label is a set of permissions.
Comparing webpage elements having asynchronous functionality
Techniques for determining differences between document object models (DOMs) received in response to asynchronous functionality calls is described herein. The techniques may include clustering elements in a webpage having asynchronous functionality. The techniques include executing asynchronous functionality calls for two of the elements that form a cluster, and receiving a document object model (DOM) in response to each of the asynchronous functionality calls. The DOMs are compared to determine whether a difference exists between the DOMs based on a predetermined threshold. If no difference exists, execution of the asynchronous functionality calls is ceased.
Providing context in functional testing of web services
Providing context in functional testing of web services. Methods of a web service are categorized into predefined categories defining interaction flows on the web, based on a semantic analysis of the names of the web methods. For each categorized web method, a testing context for the web method is created according to its category in the form of a sequence of one or more other methods of the web service that provide an appropriate context for testing the web method.
Detecting vulnerability to resource exhaustion
In an aspect of managing resource exhaustion, a method includes receiving a program code that is configured for generating a random number. The generating is identified as vulnerable to a resource exhaustion. The method also includes identifying a statement in the program code at which a value of a variable associated with the generating of the random number is affected, inserting a hooking code in the statement for monitoring the variable at the statement, and running the program code in a plurality of iterations. A consumption level of the resource is varied in the plurality of iterations. The method further includes monitoring a plurality of values of the variable in the plurality of iterations. The method also includes executing a regression analysis on the plurality of values and returning a root cause of the vulnerability.
System, method and apparatus for simultaneous definition and enforcement of access-control and integrity policies
Access-control and information-flow integrity policies are enforced in a computing system by detecting security-sensitive sinks in software code for an application running on the computing system and retrieving an access-control policy from a database accessible to the computing system. The access-control policy maps a set of access permissions within the computing system to each one of a plurality of principals. For each detected security-sensitive sink, all principals that influence that security-sensitive sink are detected and an overall access permission is assigned to each security-sensitive sink by taking the intersection of the access permission sets for all influencing principals of that security-sensitive sink. If this permission set is inadequate, an integrity violation is reported. In addition, permission labels are assigned to each value of variables used in the security-sensitive sinks. Each permission label is a set of permissions.
Using Abstract Interpretation to Correct Synchronization Faults
We describe a novel use of abstract interpretation in which the abstract domain informs a runtime system to correct synchronization failures. To this end, we first introduce a novel synchronization paradigm, dubbed corrective synchronization, that is a generalization of existing approaches to ensuring serializability. Specifically, the correctness of multi-threaded execution need not be enforced by previous methods that either reduce parallelism (pessimistic) or roll back illegal thread interleavings (optimistic); instead inadmissible states can be altered into admissible ones. In this way, the effects of inadmissible interleavings can be compensated for by modifying the program state as a transaction completes, while accounting for the behavior of concurrent transactions. We have proved that corrective synchronization is serializable and give conditions under which progress is ensured. Next, we describe an abstract interpretation that is able to compute these valid serializable post-states w.r.t. a transactions entry state by computing an under-approximation of the serializable intermediate (or final) states as the fixpoint solution over an inter-procedural control-flow graph. These abstract states inform a runtime system that is able to perform state correction dynamically. We have instantiated this setup to clients of a Java-like Concurrent Map data structure to ensure safe composition of map operations. Finally, we report early encouraging results that the approach competes with or out-performs previous pessimistic or optimistic approaches.
Payload generation for computer software testing
A method of generating test payloads for a target system includes receiving a plurality of reference programs, each reference program modelling at least one aspect of the target system, building a specification for each received reference program, each specification defining illegal states for the respective reference program, analyzing each specification to determine one or more entry constraints that would generate an illegal state from a specific input, and synthesizing one or more payloads from the determined entry constraints.
Static security analysis using a hybrid representation of string values
A hybrid string constructor includes a database configured to store a set of known concretizations. A processor is configured to compare the one or more string components to the set of known concretizations to determine string components from input string information that may be represented concretely, to abstract all string components that could not be represented concretely, and to create a hybrid string representation that includes at least one concrete string component and at least one abstracted string component. The set of known concretizations includes string configurations that cannot be interfered with by an attacker.
Detecting race condition vulnerabilities in computer software applications
Testing computer software applications is performed by identifying first and second executable portions of the computer software application, where the portions are configured to access a data resource, and where at least one of the portions is configured to write to the data resource, instrumenting the computer software application by inserting one or more instrumentation instructions into one or both of the portions, where the instrumentation instruction is configured to cause execution of the portion being instrumented to be extended by a randomly-determined amount of time, and testing the computer software application in multiple iterations, where the computer software application is executed in multiple parallel execution threads, where the portions are independently executed at least partially in parallel in different threads, and where the computer software application is differently instrumented in each of the iterations.
Application testing for security vulnerabilities
In an approach for testing an application for a security vulnerability, a processor inserts an instrumentation hook in the application to be tested, wherein the instrumentation hook is executed prior to a sink operation. A processor transmits a probe input value to the application to be tested. A processor detects a modification to the probe input value at the instrumentation hook by comparing the probe input value at the instrumentation hook to a signature value and detecting that the probe input value matches the signature value. A processor removes the sink operation from testing for the security vulnerability.
Remediation of security vulnerabilities in computer software
Processing a downgrader specification by constructing a set of candidate downgrader placement locations found within a computer software application, where each of the candidate downgrader placement locations corresponds to a transition between a different pair of instructions within the computer software application, and where each of the transitions participates in any of a plurality of data flows in a set of security-sensitive data flows within the computer software application, applying a downgrader specification to the set of candidate downgrader placement locations, and determining that the downgrader specification provides full coverage of the set of security-sensitive data flows within the computer software application if at least one candidate downgrader placement location within each of the security-sensitive data flows is a member of the set of candidate downgrader placement locations.
Modeling memory use of applications
A method includes receiving a program code at a processor. The method also includes generating, via the processor, a heap model corresponding to the program code. The method further includes detecting, via the processor, a linearizable data structure in the program code. The method also further includes modifying, via the processor, the heap model based on the detected linearizable data structure. The method also further includes analyzing, via the processor, the program code using the modified heap model.
FASE: functionality-aware security enforcement
Dynamic information-flow enforcement systems automatically protect applications against confidentiality and integrity threats. Unfortunately, existing solutions cause undesirable side effects, if not crashes, due to unconstrained modification of run-time values (e.g. anonymizing sensitive identifiers even when these are used for authentication). To address this problem, we present Functionality-Aware Security Enforcement (FASE), a lightweight approach for ef?ciently securing applications without breaking their functionality. The key idea is to let developers specify functionality constraints and then use a run-time synthesizer to replace sensitive values with constraint-compliant ones. Concretely, FASE consists of: (i) an efficient fine-grained data-flow-tracking engine, (ii) a domain-specific language (DSL) for expressing functionality constraints, (iii) a synthesizer that derives constraint-compliant values at security-sensitive operations, and (iv) an enforcement mechanism that automatically repairs illicit flows at run time. We instantiated FASE to the problem of securing Android applications. Our experiments show that the FASE system is useful in practice: Its average run-time overhead is <12%; it avoids the crashes, side effects, and run-time errors exhibited by existing solutions; and the constraints in the FASE DSL are readable and concise.
Static security analysis using a hybrid representation of string values
Methods for creating a hybrid string representation include determining string components from input string information that may be represented concretely by comparing the one or more components to a set of known concretizations using a processor. The set of known concretizations includes string configurations that cannot be interfered with by an attacker. All string components that could not be represented concretely are abstracted. A hybrid string representation is created that includes at least one concrete string component and at least one abstracted string component.
Optimizing web crawling through web page pruning
Crawling computer-based documents by performing static analysis on a computer-based document to identify within the computer-based document one or more execution vectors, where each execution vector includes a computer program segment including a call to an entity that is external to the computer-based document, and one or more additional computer program segments whose execution precedes and leads ultimately to execution of the computer program segment that includes the call to the entity, and causing any of the computer program segments in any of the execution vectors to be executed during a crawling of the computer-based document, and any computer program segment within the computer-based document that is excluded from the execution vectors to be excluded from execution during the crawling of the computer-based document.
Dagstuhl Reports, Vol. 6, Issue 5 ISSN 2192-5283
No abstract available.
Revamping JavaScript static analysis via localization and remediation of root causes of imprecision
Static analysis is challenged by the dynamic language constructs of JavaScript which often lead to unacceptable performance and/or precision results. We describe an approach that focuses on improving the practicality and accuracy of points-to analysis and call graph construction for JavaScript programs. The approach first identifies program constructs which are sources of imprecision (i.e., root causes) through monitoring the static analysis process. We then examine and suggest specific context-sensitive analyses to apply. Our technique is able to to find that the root causes comprise less than 2% of the functions in JavaScript library applications. Moreover, the specialized analysis derived by our approach finishes within a few seconds, even on programs which can not complete within 10 minutes with the original analysis.
System, method and apparatus to visually configure an analysis of a program
A method extracts views from an application program, where at least some extracted views include at least one view component, and presenting the extracted views to a user. In response to the user selecting a view component in a presented extracted view, the method presents a form to the user having a plurality of vulnerability types indicated for the selected view component and, for each vulnerability type, provides an ability for the user to set an indicator in the form as to indicate whether the view component is at least one of a source or a sink. The method further includes saving the form containing the user's input in conjunction with a user-provided label for the selected view component and a unique identification of the selected view component, and deriving an analysis policy configuration from the saved form that is formatted for use by a program security analyzer.
Directed synthesis of failing concurrent executions
Detecting concurrency-induced bugs in multithreaded libraries can be challenging due to the intricacies associated with their manifestation. This includes invocation of multiple methods, synthesis of inputs to the methods to reach the failing location, and crafting of thread interleavings that cause the erroneous behavior. Neither fuzzing-based testing techniques nor over-approximate static analyses are well positioned to detect such subtle defects while retaining high accuracy alongside satisfactory coverage. In this paper, we propose a directed, iterative and scalable testing engine that combines the strengths of static and dynamic analysis to help synthesize concurrent executions to expose complex concurrency-induced bugs. Our engine accepts as input the library, its client (either sequential or concurrent) and a specification of correctness. Then, it iteratively refines the client to generate an execution that can break the input specification. Each step of the iterative process includes statically identifying sub-goals towards the goal of failing the specification, generating a plan toward meeting these goals, and merging of the paths traversed dynamically with the plan computed statically via constraint solving to generate a new client. The engine reports full reproduction scenarios, guaranteed to be true, for the bugs it finds. We have created a prototype of our approach named MINION. We validated MINION by applying it to well-tested concurrent classes from popular Java libraries, including the latest versions of openjdk and google-guava. We were able to detect 31 real crashes across 10 classes in a total of 23 minutes, including previously unknown bugs. Comparison with three other tools reveals that combined, they report only 9 of the 31 crashes (and no other crashes beyond MINION). This is because several of these bugs manifest under deeply nested path conditions (observed maximum of 11), deep nesting of method invocations (observed maximum of 6) and multiple refinement iterations to generate the crash-inducing client.
Combining Static Code Analysis and Machine Learning for Automatic Detection of Security Vulnerabilities in Mobile Apps
Mobile devices have revolutionized many aspects of our lives. Without realizing it, we often run on them programs that access and transmit private information over the network. Integrity concerns arise when mobile applications use untrusted data as input to security-sensitive computations. Program-analysis tools for integrity and confidentiality enforcement have become a necessity. Static-analysis tools are particularly attractive because they do not require installing and executing the program, and have the potential of never missing any vulnerability. Nevertheless, such tools often have high false-positive rates. In order to reduce the number of false positives, static analysis has to be very precise, but this is in conflict with the analysis' performance and scalability, requiring a more refined model of the application. This chapter proposes Phoenix, a novel solution that combines static analysis with machine learning to identify programs exhibiting suspicious operations. This approach has been widely applied to mobile applications obtaining impressive results.
Execution of test inputs with applications in computer security assessment
A given application is instrumented to trace its execution flow. Constraints and/or transformation associated with input identified in the execution flow are mirrored on a set of candidate test payloads. The set of candidate test payloads are modified or pruned based on the execution flow of the instrumented application reaching a security operation with the input satisfying the constraints while the payloads may not. If the set of candidate test payloads is not empty at reaching the security operation, it is determined that the give application has vulnerability and a signal issuing a warning may be generated and transmitted.
Detecting stored cross-site scripting vulnerabilities in web applications
A system for detecting security vulnerabilities in web applications, the system including, a black-box tester configured to provide a payload to a web application during a first interaction with the web application at a computer server, where the payload includes a payload instruction and an identifier, and an execution engine configured to detect the identifier within the payload received during an interaction with the web application subsequent to the first interaction, and determine, responsive to detecting the identifier within the payload, whether the payload instruction underwent a security check prior to execution of the payload instruction
Automatic generation of analysis-equivalent application constructs
A computer program to be subjected to static analysis includes at least one framework, in turn including high-level code and at least one configuration file. A specification which describes run-time behavior of the program, including run-time behavior of the at least one framework including the high-level code and the at least one configuration file, is created from the computer program. Based on the specification, synthetic high-level code which accurately simulates the run-time behavior of the at least one framework including the high-level code and the at least one configuration file, without framework usage, is created. Static analysis of the computer program is carried out based on the synthetic high-level code.
Performance testing of web components using identity information
Performance testing of web components using identity information includes providing a web component for testing having business logic code and an associated authorization layer code, locating, using a processor, branches in the authorization layer code and the business logic code which are dependent on identity information, and creating, using the processor, symbolic identities with claims or attributes having values corresponding to the branch options of the located branches. The method also includes propagating the symbolic identities downstream from the branch locations through the authorization layer code and the business logic code and analyzing, using the processor, the performance of each symbolic identity.
Security testing of web applications with specialized payloads
In one embodiment, a computer-implemented method for security testing of web applications with specialized payloads includes submitting a test to a web application, where the test includes a payload with a set of constraints. A response is received from the web application. One or more constraints are derived from the response. The set of constraints of the payload are updated with the derived one or more constraints. The payload is synthesized, by a computer processor, for the updated set of constraints. The test having the synthesized payload is iterated with the updated set of constraints.
Fine-Grained User Control Over Usages Of Sensitive System Resources Having Private Data With Applications In Privacy Enforcement
A system and method whereby permission is accessed that is to be revoked for an application. The permission involves access to private data of a user via an API of an OS. It is determined, in the application, program point(s) involving access to the private data of the user via the API. For each selected one of the program point(s), code in the application is rewritten to replace a source statement, at the selected program point, that accesses the private data with another statement that allocates a mock object or value based on a type of an actual value returned by the source statement. The mock object or value does not expose the private data of the user. The application with the rewritten code is packaged as an output application able to be subsequently executed by the user, and is output for use by the user.
Fine-Grained User Control Over Usages Of Sensitive System Resources Having Private Data With Applications In Privacy Enforcement
A system and method whereby permission is accessed that is to be revoked for an application. The permission involves access to private data of a user via an API of an OS. It is determined, in the application, program point(s) involving access to the private data of the user via the API. For each selected one of the program point(s), code in the application is rewritten to replace a source statement, at the selected program point, that accesses the private data with another statement that allocates a mock object or value based on a type of an actual value returned by the source statement. The mock object or value does not expose the private data of the user. The application with the rewritten code is packaged as an output application able to be subsequently executed by the user, and is output for use by the user.
Automatic correction of security downgraders
Methods and systems for automatic correction of security downgraders. For one or more flows having one or more candidate downgraders, it is determined whether each candidate downgrader protects against all vulnerabilities associated with the candidate downgrader's respective flow. Candidate downgraders that do not protect against all of the associated vulnerabilities are transformed, such that the transformed downgraders do protect against all of the associated vulnerabilities.
Enhanced String Analysis that Improves Accuracy of Static Analysis
An apparatus and computer program product which are configured for determining, as part of a static analysis of a program, links between functions in the program and performing, as part of the static analysis, string analysis on strings used in the program to determine additional links between the functions in the program. The apparatus and computer program product are further configured for outputting, as part of the static analysis, indications of at least the links between the functions and the additional links between the functions.
Predicting and using utility of script execution in functional web crawling and other crawling
A program is executed that includes multiple script functions. For a selected script function, the following are performed during program execution. It is determined whether the selected script function should or should not be executed based on a utility corresponding to the selected script function. The utility was determined prior to determining whether the selected script function should be executed. The selected script function is executed in response to a determination the selected script function should be executed. Execution of the selected script function is skipped in response to a determination the selected script function should not be executed. These techniques may be applied in real-time to crawl a program such as a webpage or may be applied using offline learning followed by a real-time crawling of the program. Apparatus, methods, and program products are disclosed.
Hyperlink data presentation
A method of presenting hyperlink data. The method comprises identifying when a web browser running on a web browser client retrieves, in response to a web document data request submitted to a target server, a first web document data for displaying a first web document containing a hyperlink having a label for display and a target destination defining an address of a second web document, evaluating a risk from content of the second web document, generating by the web browser to a reference evaluation indication of the risk, and processing the web document data and the reference evaluation indication by the web browser for generating a presentation on the client terminal which combines the first web document data and the reference evaluation indication such that when the reference evaluation indication is presented when the label is presented by the web browser.
Identifying stored vulnerabilities in a web service
A computer identifies each web method, of a web service, declared in a web services description language (WSDL) file. The computer adds a node within a directed graph for each web method identified. The computer identifies pairs of web methods declared in the WSDL file in which a match exists between an output parameter of one of the web methods and an input parameter of another one of the web methods. The computer adds an edge within the directed graph for each of the pairs of web methods identified. The computer generates one or more sequences of web methods based on nodes connected by edges within the directed graph, wherein each of the one or more sequences includes at least one of the pairs of web methods identified. The computer tests each of the one or more sequences of web methods to identify stored vulnerabilities in the web service.
Ipa: Improving predictive analysis with pointer analysis
Predictive analysis, recently proposed for race detection, guarantees to report no false positives and achieves good coverage. Predictive analysis starts with the trace of an execution and mutates the schedule order of the trace to ``predict'' the executions that expose the hidden races. Ideally, the predictive analysis should allow the schedule mutation to change the memory location accessed by the field access, which helps meet the ``same memory location'' requirement of the data race. However, existing predictive approaches, including causality-preserving approaches and symbolic approaches, lack this capability. We propose the first predictive analysis that allows changing the accessed locations. The key challenge is that modeling of the field accesses relies on the location, which may however become unknown due to schedule mutation. We solve this challenge through a novel combination of predictive analysis and pointer analysis. Furthermore, unlike previous work, our analysis applies a hybrid encoding scheme to increase practical applicability. We have implemented our approach as a prototype IPA, and compared it against the most recent predictive analysis over a set of popular Java applications. Our experimental evaluation confirms the effectiveness of our approach:IPA is able to find close to 2X as many races as previous approaches.
Optimizing web crawling through web page pruning
Crawling computer-based documents by performing static analysis on a computer-based document to identify within the computer-based document one or more execution vectors, where each execution vector includes a computer program segment including a call to an entity that is external to the computer-based document, and one or more additional computer program segments whose execution precedes and leads ultimately to execution of the computer program segment that includes the call to the entity, and causing any of the computer program segments in any of the execution vectors to be executed during a crawling of the computer-based document, and any computer program segment within the computer-based document that is excluded from the execution vectors to be excluded from execution during the crawling of the computer-based document.
Security testing using semantic modeling
Optimized testing of vulnerabilities in an application implemented by a method includes generating a first probe directed to determine whether an application is vulnerable to a first type of attack; analyzing one or more responses from the application based on the application responding to the first probe; in response to determining that the one or more responses from the application validate a first hypothesis about one or more vulnerabilities associated with the application, and generating at least a second probe to further verify the first hypothesis. The second probe focuses on discovering additional details about the application's vulnerabilities to the first type of attack or a second type of attack.
Security testing using semantic modeling
Optimized testing of vulnerabilities in an application implemented by a method includes generating a first probe directed to determine whether an application is vulnerable to a first type of attack; analyzing one or more responses from the application based on the application responding to the first probe; in response to determining that the one or more responses from the application validate a first hypothesis about one or more vulnerabilities associated with the application, and generating at least a second probe to further verify the first hypothesis. The second probe focuses on discovering additional details about the application's vulnerabilities to the first type of attack or a second type of attack.
Rule matching in the presence of languages with no types or as an adjunct to current analyses for security vulnerability analysis
A method includes a computing system reading a rule file that includes one or more rules having specified paths to methods, such that each method corresponds to one of a sink, source, or sanitizer. The method includes the computing system matching the methods to corresponding ones of sinks, sources, or sanitizers determined through a static analysis of an application. The static analysis determines at least flows from sources of information to sinks that use the information. The method includes the computing system, using the sinks, sources, and sanitizers found by the matching, performing a taint analysis to determine at least tainted flows from sources to sinks, the tainted flows being flows that pass information to sinks without the information being endorsed by a sanitizer. Apparatus and program products are also shown.
Z3strBV: A Solver for a Theory of Strings and Bit-vectors
We present a solver for a many-sorted first-order quantifier-free theory Tw,bv of string equations, string length represented as bit-vectors, and bit-vector arithmetic aimed at formal verification, automated testing, and security analysis of C/C++ applications. Our key motivation for building such a solver is the observation that existing string solvers are not efficient at modeling the string/bit-vector combination. Current approaches either reduce strings to bit-vectors and use a bit-vector solver as a backend, or model bit-vectors as natural numbers and use a solver for the combined theory of strings and natural numbers. Both these approaches are inefficient for different reasons. Modeling strings as bit-vectors destroys structure inherent in string equations thus missing opportunities for efficiently deciding such formulas, and modeling bit-vectors as natural numbers is known to be inefficient. Hence, there is a clear need for a solver that models strings and bit-vectors natively. Our solver Z3strBV is a decision procedure for the theory Tw,bv combining solvers for bit-vector and string equations. We demonstrate experimentally that Z3strBV is significantly more efficient than reduction of string/bit-vector constraints to strings/natural numbers. Additionally, we prove decidability for the theory Tw,bv. We also propose two optimizations which can be adapted to other contexts. The first accelerates convergence on a consistent assignment of string lengths, and the second, dubbed library-aware SMT solving, fixes summaries for built-in string functions (e.g., {\tt strlen} in C/C++), which Z3strBV uses directly instead of analyzing the functions from scratch each time. Finally, we demonstrate experimentally that Z3strBV is able to detect nontrivial overflows in real-world system-level code, as confirmed against 7 security vulnerabilities from CVE and Mozilla database.
Crawling computer-based objects
Crawling computer-based objects by identifying a dependency between a first portion of a computer-based object set and a second portion of the computer-based object set, where the second portion is data-dependent on the first portion, and responsive to identifying the dependency, effecting a crawling of the first portion and thereafter a crawling of the second portion.
Auto-tuning program analysis tools using machine learning
Machine learning (ML) significantly reduces false alarms generated by an automated analysis tool performing static security analysis. Using either user-supplied or system-generated annotation of particular findings, a hypothesis is generated about how to classify other static analysis findings. The hypothesis is implemented as a machine learning classifier. To generate the classifier, a set of features are abstracted from a typical witness, and the system compares feature sets against one another to determine a set of weights for the classifier. The initial hypothesis is then validated against a second set of findings, and the classifier is adjusted as necessary based on how close it fits the new data. Once the approach converges on a final classifier, it is used to filter remaining findings in the report.
Auto-tuning program analysis tools based on user feedback
User-guided machine learning (ML) significantly reduces false alarms generated by an automated analysis tool performing static security analysis. User interactivity involves initial review and annotation of findings (witnesses) in a report generated by the analysis tool. Those annotated findings are then used by the system to generate a hypothesis about how to further classify the static analysis findings in the report. The hypothesis is implemented as a machine learning classifier. To generate the classifier, a set of features are abstracted from a typical witness, and the system compares feature sets against one another to determine a set of weights for the classifier. The initial hypothesis is then validated against a second set of user-annotated findings, and the classifier is adjusted as necessary based on how close it fits the new data. Once the approach converges on a final classifier, it is used to filter remaining findings in the report
Determining privacy granularity
Techniques for determining privacy granularity in a data flow are described herein. The techniques may include identifying a data flow source statement within a computer program and identifying a feature read at the source statement. The feature includes private data of a private data category. The techniques include identifying a sink of the data flow and determining a value associated with the feature flowing into the sink. The value indicates a degree of granularity of the private data flowing into the sink.
Detecting multistep operations when interacting with web applications
Detecting multistep operations when interacting with web applications is performed by identifying a set of multiple web pages of a web application, where the web pages in the set of multiple web pages are sequentially navigable, identifying a group of multiple web page elements at the same relative location in each of the web pages in the set of multiple web pages, determining that the identified groups of web page elements are similar to each other in accordance with a predefined similarity criterion, identifying an element that is common to each identified group of web page elements, and determining that a characteristic of the element is uniquely varied in each of the identified groups of web page elements.
Determination and classification of defense measures in web applications
Techniques for determining classifications of defense measures as described herein. Security tokens are identified to be used to test defense measures of a web application. Combinations of security tokens are determined, wherein the combinations of security tokens are related to classifications of the defense measures. A combination is executed at an input point of the web application. Based on the output of the web application received in response to the executed combination, a classification for a defense measure of the web application is determined.
Eavesdropping and obfuscation techniques for smartphones
Mobile apps often collect and share personal data with untrustworthy third-party apps, which may lead to data misuse and privacy violations. Most of the collected data originates from sensors built into the mobile device, where some of the sensors are treated as sensitive by the mobile platform while others permit unconditional access. Examples of privacy-prone sensors are the microphone, camera and GPS system. Access to these sensors is always mediated by protected function calls. On the other hand, the light sensor, accelerometer and gyroscope are considered innocuous. All apps have unrestricted access to their data. Unfortunately, this gap is not always justified. State-of-the-art privacy mechanisms on Android provide inadequate access control and do not address the vulnerabilities that arise due to unmediated access to so-called innocuous sensors on smartphones. We have developed techniques to demonstrate these threats. As part of our demonstration, we illustrate possible attacks using the innocuous sensors on the phone. As a solution, we present ipShield, a framework that provides users with greater control over their resources at runtime so as to protect against such attacks. We have implemented ipShield by modifying the AOSP.
Pinpointing mobile malware using code analysis
Mobile malware has recently become an acute problem. Existing solutions either base static reasoning on syntactic properties, such as exception handlers or configuration fields, or compute data-flow reachability over the program, which leads to scalability challenges. We explore a new and complementary category of features, which strikes a middleground between the above two categories. This new category focuses on security-relevant operations (communication, lifecycle, etc) - and in particular, their multiplicity and happens-before order - as a means to distinguish between malicious and benign applications. Computing these features requires semantic, yet lightweight, modeling of the program's behavior. We have created a malware detection system for Android, MASSDROID, that collects traces of security-relevant operations from the call graph via a scalable form of data-flow analysis. These are reduced to happens-before and multiplicity features, then fed into a supervised learning engine to obtain a malicious/benign classification. MASSDROID also embodies a novel reporting interface, containing pointers into the code that serve as evidence supporting the determination. We have applied MASSDROID to 35,000 Android apps from the wild. The results are highly encouraging with an F-score of 95% in standard testing, and >90% when applied to previously unseen malware signatures. MASSDROID is also efficient, requiring about two minutes per app. MASSDROID is publicly available as a cloud service for malware detection.
Cognitive mobile security: invited conference keynote
Mobile devices carry a number of vulnerabilities that, when exploited, can result in proprietary-data leakage, data alteration, fraudulent transactions and, in extreme cases, physical damage to the user and surroundings. Such attacks can be instigated by both outsiders and insiders, and can leverage vulnerabilities embedded in the hardware and software components of the device, as well as risky behavioral actions undertaken by the legitimate user of the device. Existing mobile security management solutions offer a wide range of configuration, tracking, and management features via device and container management, policy-based configuration, single sign-on, application whitelisting and/or blacklisting, as well as reputation and anti-malware services. A primary feature that none of the existing solutions has is \emph{context-aware anomaly detection}. We propose a novel cognitive solution for mobile security based on context awareness. Our solution focuses on mobile management tools that understand long-term context-aware behavior anomalies on multiple devices.
A framework for automatic anomaly detection in mobile applications
It is standard practice in enterprises to analyze large amounts of logs to detect software failures and malicious behaviors. Mobile applications pose a major challenge to centralized monitoring as network and storage limitations prevent fine-grained logs to be stored and transferred for off-line analysis. In this paper we introduce EMMA, a framework for automatic anomaly detection that enables security analysis as well as in-the-field quality assurance for enterprise mobile applications, and incurs minimal overhead for data exchange with a back-end monitoring platform. EMMA instruments binary applications with a lightweight anomaly-detection layer that reveals failures and security threats directly on mobile devices, thus enabling corrective measures to be taken promptly even when the device is disconnected. In our empirical evaluation, EMMA detected failures in unmodified Android mobile applications.
Improving design validation of mobile application user interface implementation
During the mobile app development cycle, User-Interface (UI) components rendered by the mobile app are typically validated against high-fidelity mockups by manually comparing screens from a mockup design to screens developed in the app. This validation most often takes the time of the lead designer, resulting in many post-sprint defects and tasks that must be folded into the next sprint iteration. To improve this process, an engineer should be able to validate layout as part of the acceptance criteria for each task submitted, providing a more complete UI, less defects and reduced cost for the app development. We propose a system of improvements for moving this process forward by automatically validating layout. The system is based on techniques from computer vision, in conjunction with style policies, which together facilitate validation of design layout prior to submitting completed task work, thereby reducing the overall cost of developing UI designs.
Enhanced string analysis that improves accuracy of static analysis
An apparatus and computer program product which are configured for determining, as part of a static analysis of a program, links between functions in the program and performing, as part of the static analysis, string analysis on strings used in the program to determine additional links between the functions in the program. The apparatus and computer program product are further configured for outputting, as part of the static analysis, indications of at least the links between the functions and the additional links between the functions.
Method, apparatus and computer program product providing performance and energy optimization for mobile computing
A method to share a computation task among a plurality of devices including at least one mobile device. The method includes estimating a cost to perform a computation task on a data set. If the estimated cost is greater than a threshold cost, the method further includes forming an ad-hoc wireless network comprised of a plurality of devices; downloading a portion of the data set to individual ones of the devices; performing a computation task by each device on the downloaded portion of the data set; and wirelessly transferring a result of the computation task from each device to all other devices of the network. The method can be performed by execution of an application program stored in mobile devices configured for local area wireless connectivity with neighboring mobile devices and for wireless connectivity to a remote server from which the portion of the data set is downloaded.
Detecting error states when interacting with web applications
Detecting error states when interacting with web applications is performed by accessing a first web page of a web application, determining that the first web page includes an input validation operation, configuring an input to cause the input validation operation to effect an error state, providing the input to the first web page, thereby effecting the error state, identifying a feature that is absent from the first web page before the input is provided to the first web page and present in the first web page after the input is provided to the first web page, and detecting that a second web page of the web application is in an error state if the feature is present in the second web page.
Method, apparatus and computer program product providing performance and energy optimization for mobile computing
A mobile device includes a computer-readable medium storing computer program instructions, a data processor to execute the instructions, and communication circuitry configured for local area wireless connectivity with neighboring mobile devices and for wireless connectivity to a remote server from which at least a portion of a data set is downloaded. Execution of the computer program instructions results in estimating a cost to perform a computation task on the data set. If the estimated cost is greater than a threshold cost, an ad-hoc wireless network is formed with at least one other mobile device and the mobile device downloads a portion of the data set assigned to the mobile device. The mobile device then performs a computation task on the downloaded portion of the data set and wirelessly transfers a result of the computation task to the at least one other mobile device of the ad-hoc wireless network.
Identifying client states
A method for identifying client states, receives a set of paths representative of a document object model (DOM) associated with a web page of a rich internet application and for each path in the set of paths received, extracts a subtree, as subtree X, for a current path. The method traverses all known sub-paths under the current path and delete corresponding subtrees from subtree X and reads contents of and determines states of subtree X to form a state X. The state X is added to a set of current states and responsive to a determination no more paths exist, returns the set of current states of the rich internet application.
Automated testing of websites based on mode
Examples of techniques for testing websites are described herein. In one example, a method for testing a website includes receiving, via a processor, a website address of the website to be tested. The method can include determining, via the processor, whether the website is in a staging mode or a production mode. The method can also include configuring, via the processor, a testing application to test the website according to the determined mode.
Remediation of security vulnerabilities in computer software
Processing a downgrader specification by constructing a set of candidate downgrader placement locations found within a computer software application, where each of the candidate downgrader placement locations corresponds to a transition between a different pair of instructions within the computer software application, and where each of the transitions participates in any of a plurality of data flows in a set of security-sensitive data flows within the computer software application, applying a downgrader specification to the set of candidate downgrader placement locations, and determining that the downgrader specification provides full coverage of the set of security-sensitive data flows within the computer software application if at least one candidate downgrader placement location within each of the security-sensitive data flows is a member of the set of candidate downgrader placement locations.
Generating coverage metrics for black-box testing
Generating coverage metrics for black-box testing includes performing static analysis of a program code to be tested. The static analysis includes identifying variables whose value depends on inputs of the program code. Code blocks are inserted into the program code to be tested. The code blocks insert vulnerabilities into the code at locations where the variables are modified. The code blocks violate one or more properties to be tested. A testing scan is applied to the program code and vulnerabilities are located by the test. A coverage metric is output based on the ratio of the located vulnerabilities to the total number of inserted vulnerabilities in the program code.
System and method for static detection and categorization of information-flow downgraders
A system and method for static detection and categorization of information-flow downgraders includes transforming a program stored in a memory device by statically analyzing program variables to yield a single assignment to each variable in an instruction set. The instruction set is translated to production rules with string operations. A context-free grammar is generated from the production rules to identify a finite set of strings. An information-flow downgrader function is identified by checking the finite set of strings against one or more function specifications.
Optimizing test data payload selection for testing computer software applications that employ data sanitizers and data validators
Testing computer software applications is implemented by probing a computer software application to determine the presence in the computer software application of any data-checking features, and applying a rule to the data-checking features that are determined to be present in the computer software application, thereby producing a testing set of inputs. The testing set includes any sets of inputs that were used to test sets of data-checking software, where each of the sets of data-checking software includes one or more data sanitizers and/or data validators, and where the rule is configured to produce the testing set to include one or more of the sets of inputs when the rule is applied to any of the data-checking features. The computer software application is tested using the testing set.
Building reusable function summaries for frequently visited methods to optimize data-flow analysis
A method includes inspecting function summaries generated during a static analysis of a program and identifying a set of function summaries for a same method that have structural similarities. The method includes replacing the set of structurally similar summaries with a coarse summary. The method further includes using the coarse summary in subsequent static analysis operations. Apparatus and program products are also disclosed.
Quantitative analysis of information leakage vulnerabilities
A method includes recording, during execution of a program and by a computing system, concrete values exhibited at source and sink statements in the program. The source statements read confidential information and the sink statements release the confidential information to an outside environment. The method includes determining, by the computing system, using at least the recorded concrete values and source-sink pairs whether information leakage meeting one or more quantitative criteria occurs by the program. Apparatus and program products are also disclosed.
Static analysis for discovery of timing attack vulnerabilities in a computer software application
Discovering timing attack vulnerabilities in a computer software application by statically analyzing instructions of a computer software application to identify multiple possible execution paths traversing any of the instructions, calculating, for each of the possible execution paths, a cost associated with the execution of the instructions traversed by the possible execution path, comparing the costs of at least two of the possible execution paths having inputs of the same size, and identifying as a timing attack vulnerability any of the compared possible execution paths whose cost differs, by at least a predetermined amount, from the cost of any other of the compared possible execution paths.
Static analysis for discovery of timing attack vulnerabilities in a computer software application
Discovering timing attack vulnerabilities in a computer software application by statically analyzing instructions of a computer software application to identify multiple possible execution paths traversing any of the instructions, calculating, for each of the possible execution paths, a cost associated with the execution of the instructions traversed by the possible execution path, comparing the costs of at least two of the possible execution paths having inputs of the same size, and identifying as a timing attack vulnerability any of the compared possible execution paths whose cost differs, by at least a predetermined amount, from the cost of any other of the compared possible execution paths.
Techniques for web service black box testing
A technique for synthesizing tests from a Web service document includes locating at least one parameter for at least one client to server function call in a Web service document. Client validation constraints for the at least one parameter are discovered. Server validation constraints for the at least one parameter in the Web service document are discovered. At least one range for the at least one parameter that will be accepted by the server and not be accepted by the client is discovered. Tests using parameter values from the discovered at least one range are synthesized.
Determination and classification of defense measures in web applications
Techniques for determining classifications of defense measures as described herein. Security tokens are identified to be used to test defense measures of a web application. Combinations of security tokens are determined, wherein the combinations of security tokens are related to classifications of the defense measures. A combination is executed at an input point of the web application. Based on the output of the web application received in response to the executed combination, a classification for a defense measure of the web application is determined.
Synergies among Testing, Verification, and Repair for Concurrent Programs (Dagstuhl Seminar 16201)
This report documents the program and the outcomes of Dagstuhl Seminar 16201 "Synergies among Testing, Verification, and Repair for Concurrent Programs". This seminar builds upon, and is inspired by, several past seminars on program testing, verification, repair and combinations thereof. These include Dagstuhl Seminar 13021 "Symbolic Methods in Testing"; Dagstuhl Seminar 13061 "Fault Prediction, Localization and Repair"; Dagstuhl Seminar 14171 "Evaluating Software Verification Systems: Benchmarks and Competitions"; Dagstuhl Seminar 14352 "Next Generation Static Software Analysis Tools"; Dagstuhl Seminar 14442 "Symbolic Execution and Constraint Solving"; and Dagstuhl Seminar 15191 "Compositional Verification Methods for Next-Generation Concurrency". These were held in January 2013; February 2013; April 2014; August 2014; October 2014; and May 2015, respectively. Two notable contributions of Dagstuhl Seminar 16201, which distinguish it from these past seminars, are (i) the focus on concurrent programming, which introduces significant challenges to testing, verification and repair tools, as well as (ii) the goal of identifying and exploiting synergies between the testing, verification and repair research communities in light of common needs and goals.
After-the-fact configuration of static analysis tools able to reduce user burden
A method includes mapping, based on a first mapping from possible security findings to possible configuration-related sources of imprecision, actual security findings from a static analysis of a program to corresponding configuration-related sources of imprecision, the mapping of the actual security findings creating a second mapping. A user is requested to configure selected ones of the configuration-related sources of imprecision from the second mapping. Responsive to a user updating configuration corresponding to the selected ones of the configuration-related sources of imprecision, security analysis results are updated for the static analysis of the program at least by determining whether one or more security findings from the security analysis results are no longer considered to be vulnerable based on the updated configuration by the user. The updated security analysis results are output. Apparatus and program products are also disclosed.
Detection of DOM-based cross-site scripting vulnerabilities
Testing a Web-based application for security vulnerabilities. At least one client request including a payload having a unique identifier can be communicated to the Web-based application. Response HTML and an associated Document Object Model (DOM) object can be received from the Web-based application. Content corresponding to the payload can be identified in the DOM object via the unique identifier. A section of the DOM object including the payload can be identified as un-trusted.
Runtime protection of web services
Protecting a runtime Web service application. A web service application is instrumented to log its operation and allow recreation of its execution trace. Trace point vulnerabilities are identified using one or more data payloads. Candidate trace point operations associated with the trace point vulnerabilities are identified. Supplementary candidate operations are computed based on the existing trace point operations and the one or more data payloads. The Web service application is further instrumented with the one or more supplementary candidate operations.
Partitioning of program analyses into sub-analyses using dynamic hints
An exemplary apparatus and computer program product are disclosed which employ a method that includes performing a first static analysis to locate elements within a program and instrumenting the program to enable a subsequent dynamic analysis based on the located elements. The method includes executing the instrumented program and performing during execution analysis to determine individual sets of statements in the program affected by a corresponding element. The method includes partitioning the sets of statements into partitions based on one or more considerations, each partition including one or more of the elements. The method includes performing a second static analysis on the partitions of the program to produce results and outputting the results. The method may be performed for, e.g., security (e.g., taint) analysis, buffer overflow analysis, and typestate analysis.
Importance-based call graph construction
Call graph construction systems that utilize computer hardware are presented including: a processor; a candidate pool configured for representing a number of calls originating from a root node of a computer software application; an importance value assigner configured for assigning an importance value for any of the number of calls represented in the candidate pool; a candidate selector configured for selecting from the number of calls represented in the candidate pool for inclusion in a call graph based on a sufficient importance value; and an importance value adjuster configured for adjusting the importance value of any call represented in the call graph.
Determining the vulnerability of computer software applications to attacks
Determining the vulnerability of computer software applications to attacks by identifying a defense-related variable within a computer software application that is assigned results of a defense operation defending against a predefined type of attack, identifying a control-flow predicate dominating a security-sensitive operation within the application, identifying a data-flow dependent variable in the application that is data-flow dependent on the defense-related variable, determining whether the control-flow predicate uses the data-flow dependent variable to make a branching decision and whether a control-flow path leading to the security-sensitive operation is taken only if the data-flow dependent variable is compared against a value of a predefined type, determining that the security-sensitive operation is safe from the attack if both control-flow conditions are true, and determining that the application is safe from the attack if all security-sensitive operations in the application are determined to be safe from the attack.
Morphdroid: fine-grained privacy verification
Mobile devices are rich in sensors, such as a Global Positioning System (GPS) tracker, microphone and camera, and have access to numerous sources of personal information, including the device ID, contacts and social data. This richness increases the functionality of mobile apps, but also creates privacy threats. As a result, different solutions have been proposed to verify or enforce privacy policies. A key limitation of existing approaches is that they reason about privacy at a coarse level, without accounting for declassification rules, such that the location for instance is treated as a single unit of information without reference to its many fields. As a result, legitimate app behaviors --- such as releasing the user's city rather than exact address --- are perceived as privacy violations, rendering existing analyses overly conservative and thus of limited usability. In this paper, we present MorphDroid, a novel static analysis algorithm that verifies mobile applications against fine-grained privacy policies. Such policies define constraints over combinations of fine-grained units of private data. Specifically, through a novel design, MorphDroid tracks flows of fine-grained privacy units while addressing important challenges, including (i) detection of correlations between different units (e.g. longitude and latitude) and (ii) modeling of semantic transformations over private data (e.g. conversion of the location into an address). We have implemented MorphDroid, and present a thorough experimental evaluation atop a comprehensive benchmark suite for Android static and dynamic analyses (DroidBench), as well as the 500 top-popular Google Play applications in 2014. Our experiments involve a spectrum of 5 security policies, ranging from a strict coarse-grained policy to a more realistic fine-grained policy that accounts for declassification rules. The experiment on DroidBench shows that MorphDroid achieves precision and recall scores of over 90%. The experiments on popular apps show that the gap between policies is dramatic, the most conservative policy yielding warnings on 171 of the applications (34%), and the more realistic policy flagging only 4 of the applications as misbehaved (< 1%). In addition, MorphDroid exhibits good performance with an average analysis time of < 20 seconds, where on average apps consist of 1.4M lines of code.
Progressive black-box testing of computer software applications
Testing computer software applications by performing a first black-box test on a computer software application, identifying any instructions of the computer software application that were reached by a payload of the first black-box test, determining a degree of success of the first black-box test in accordance with predefined success criteria, determining whether any of the instructions that were reached by the payload changed after performing the first black-box test, deciding whether to perform a second black-box test on the computer software application, where the deciding whether to perform the second black-box test is based on whether any of the instructions that were reached by the payload of the first black-box test changed after performing the first black-box test, and the degree of success of the first black-box test.
Progressive black-box testing of computer software applications
Testing computer software applications by performing a first black-box test on a computer software application, identifying any instructions of the computer software application that were reached by a payload of the first black-box test, determining a degree of success of the first black-box test in accordance with predefined success criteria, determining whether any of the instructions that were reached by the payload changed after performing the first black-box test, deciding whether to perform a second black-box test on the computer software application, where the deciding whether to perform the second black-box test is based on whether any of the instructions that were reached by the payload of the first black-box test changed after performing the first black-box test, and the degree of success of the first black-box test.
Static analysis of computer software applications having a model-view-controller architecture
Preparing a computer software application for static analysis by identifying a control flow within a model portion of a computer software application having a model-view-controller architecture, where the control flow passes a value to a controller portion of the computer software application, analyzing a declarative specification of the controller portion of the computer software application to identify a view to which the controller portion passes control based on the value, and synthesizing a method within the computer software application, where the method calls the view.
Partitioning of Program Analyses into Sub-Analyses Using Dynamic Hints
An exemplary apparatus and computer program product are disclosed which employ a method that includes performing a first static analysis to locate elements within a program and instrumenting the program to enable a subsequent dynamic analysis based on the located elements. The method includes executing the instrumented program and performing during execution analysis to determine individual sets of statements in the program affected by a corresponding element. The method includes partitioning the sets of statements into partitions based on one or more considerations, each partition including one or more of the elements. The method includes performing a second static analysis on the partitions of the program to produce results and outputting the results. The method may be performed for, e.g., security (e.g., taint) analysis, buffer overflow analysis, and typestate analysis
Partitioning of program analyses into sub-analyses using dynamic hints
An exemplary method includes performing a first static analysis to locate elements within a program and instrumenting the program to enable a subsequent dynamic analysis based on the located elements. The method includes executing the instrumented program and performing during execution analysis to determine individual sets of statements in the program affected by a corresponding element. The method includes partitioning the sets of statements into partitions based on one or more considerations, each partition including one or more of the elements. The method includes performing a second static analysis on the partitions of the program to produce results and outputting the results. The method may be performed for, e.g., security (e.g., taint) analysis, buffer overflow analysis, and typestate analysis. Apparatus and program products are also disclosed.
Automatic detection, correction, and visualization of security vulnerabilities in mobile apps
Mobile devices have revolutionized many aspects of our lives. We use them as portable computers and, often without realizing it, we run various types of security-sensitive programs on them, such as personal and enterprise email and instant-messaging applications, as well as social, banking, insurance and retail programs. These applications access and transmit over the network numerous pieces of private information. Guaranteeing that such information is not exposed to unauthorized observers is very challenging given the level of complexity that these applications have reached. Furthermore, using program-analysis tools with out-of-the-box configurations in order to detect confidentiality violations may not yield the desired results because only a few pieces of private data, such as the device's ID and geographical location, are obtained from standard sources. The majority of confidentiality sources (such as credit-card and bank-account numbers) are application-specific and require careful configuration. This paper presents Astraea, a privacy-enforcement system for Android and iOS that dynamically detects and repairs leakage of private data originating from standard as well as application-specific sources. Astraea features several novel contributions: (i) it allows for visually configuring, directly atop the application's User Interface (UI), the fields that constitute custom sources of private data; (ii) it relies on application-level instrumentation, without interfering with the underlying operating system; (iii) it performs an enhanced form of value-similarity analysis to detect and repair data leakage even when sensitive data has been encoded or hashed, and (iv) it displays the results of the privacy analysis on top of a visual representation of the application's UI.
ShamDroid: gracefully degrading functionality in the presence of limited resource access
Given a program whose functionality depends on access to certain external resources, we investigate the question of how to gracefully degrade functionality when a subset of those resources is unavailable. The concrete setting motivating this problem statement is mobile applications, which rely on contextual data (e.g., device identifiers, user location and contacts, etc.) to fulfill their functionality. In particular, we focus on the Android platform, which mediates access to resources via an installation-time permission model. On the one hand, granting an app the permission to access a resource (e.g., the device ID) entails privacy threats (e.g., releasing the device ID to advertising servers). On the other hand, denying access to a resource could render the app useless (e.g., if inability to read the device ID is treated as an error state). Our goal is to specialize an existing Android app in such a way that it is disabled from accessing certain sensitive resources (or contextual data) as specified by the user, while still being able to execute functionality that does not depend on those resources. We present ShamDroid, a program transformation algorithm, based on specialized forms of program slicing, backwards static analysis and constraint solving, that enables the use of Android apps with partial permissions. We rigorously state the guarantees provided by ShamDroid w.r.t. functionality maximization. We provide an evaluation over the top 500 Google Play apps and report on an extensive comparative evaluation of ShamDroid against three other state-of-the-art solutions (APM, XPrivacy, and Google App Ops) that mediate resource access at the system (rather than app) level. ShamDroid performs better than all of these tools by a significant margin, leading to abnormal behavior in only 1 out of 27 apps we manually investigated, compared to the other solutions, which cause crashes and abnormalities in 9 or more of the apps. This demonstrates the importance of performing app-sensitive mocking.
Web testing tools system and method
A method, computer program product, and computer system for analyzing, by a computing device, client-side code of a web component. An input constraint of the web component is identified based upon, at least in part, analyzing the client-side code of the web component. One or more input values within the input constraint are generated based upon, at least in part, the input constraint.
Mitigating security risks via code movement
A method includes performing on a computing system a source-to-sink reachability analysis of code of an application. The reachability analysis is performed using a static analysis of the code and determines flows from sources of information to sinks that use the information. The method includes determining scopes for corresponding security sensitive operations using the determined flows, each of the security sensitive operations corresponding to statements in the code and one or more flows. A scope for a security sensitive operation includes a block of statements in the code that correspond to a set of one or more flows ending at a sink. The method includes, for each of one or more selected scopes, moving statements in a corresponding block of statements that are independent of a security sensitive operation in the block to code before or after the block. Apparatus and program products are also disclosed.
Comparing source and sink values in security analysis
Techniques for determining differences between source and sink values are described herein. The techniques may include identifying a data-flow source statement within a computer program, and recording a value read at the source statement. The techniques may include identifying a sink of the data flow, and record a value flowing into the sink. The source value may be compared to the sink value to determine whether a potential security leak exists.
Comparing source and sink values in security analysis
Techniques for determining differences between source and sink values are described herein. The techniques may include identifying a data-flow source statement within a computer program, and recording a value read at the source statement. The techniques may include identifying a sink of the data flow, and record a value flowing into the sink. The source value may be compared to the sink value to determine whether a potential security leak exists.
Privacy analysis of android apps: implicit flows and quantitative analysis
A static analysis is presented, based on the theory of abstract interpretation, for verifying privacy policy compliance by mobile applications. This includes instances where, for example, the application releases the users location or device ID without authorization. It properly extends previous work on datacentric semantics for verification of privacy policy compliance by mobile applications by (i) tracking implicit information flow, and (ii) performing a quantitative analysis of information leakage. This yields to a novel combination of qualitative and quantitative analyses of information flows in mobile applications.
Privacy Analysis of Android Apps: Implicit Flows and Quantitative Analysis
A static analysis is presented, based on the theory of abstract interpretation, for verifying privacy policy compliance by mobile applications. This includes instances where, for example, the application releases the users location or device ID without authorization. It properly extends previous work on datacentric semantics for verification of privacy policy compliance by mobile applications by (i) tracking implicit information flow, and (ii) performing a quantitative analysis of information leakage. This yields to a novel combination of qualitative and quantitative analyses of information flows in mobile applications.
Progressive static security analysis
A disclosed method includes determining modifications have been made to a program and deriving data flow seeds that are affected by the modifications. The method includes selecting one of the data flow seeds that are affected by the modifications or data flow seeds that are not affected by the modifications but that are part of flows that are affected by the modifications and performing a security analysis on the program. The security analysis includes tracking flows emanating from the selected data flow seeds to sinks terminating the flows. The method includes outputting results of the security analysis. The results comprise one or more indications of security status for one or more of the flows emanating from the selected data flow seeds. At least the deriving, selecting, and performing are performed using a static analysis of the program. Apparatus and program products are also disclosed.
Optimizing test data payload selection for testing computer software applications via computer networks
Testing a computer software application by configuring a first computer to execute a copy of data-checking software used by a computer software application at a second computer, processing a first copy of a test data payload using the data-checking software at the first computer, where the test data payload is configured to test for an associated security vulnerability, determining that the first copy of the test data payload is endorsed by the data-checking software at the first computer for further processing, and sending a second copy of the test data payload via a computer network to the computer software application at the second computer for processing threat.
Optimizing test data payload selection for testing computer software applications via computer networks
Testing a computer software application by configuring a first computer to execute a copy of data-checking software used by a computer software application at a second computer, processing a first copy of a test data payload using the data-checking software at the first computer, where the test data payload is configured to test for an associated security vulnerability, determining that the first copy of the test data payload is endorsed by the data-checking software at the first computer for further processing, and sending a second copy of the test data payload via a computer network to the computer software application at the second computer for processing threat.
Automated testing of applications with scripting code
A novel system, computer program product, and method are disclosed for feedback-directed automated test generation for programs, such as JavaScript, in which execution is monitored to collect information that directs the test generator towards inputs that yield increased coverage. Several instantiations of the framework are implemented, corresponding to variations on feedback-directed random testing, in a tool called Artemis.
Enforcement of data privacy to maintain obfuscation of certain data
A computer-readable medium is disclosed that tangibly embodies a program of machine-readable instructions executable by a digital processing apparatus to perform operations including determining whether data to be released from a database is associated with one or more confidential mappings between sets of data in the database. The operations also include, in response to the data being associated with the one or more confidential mappings, determining whether release of the data meets one or more predetermined anonymity requirements of an anonymity policy. Methods and apparatus are also disclosed.
Using a heuristically-generated policy to dynamically select string analysis algorithms for client queries
A method for dynamically selecting string analysis algorithms can begin with the training of the dynamic string analysis handler of a string analysis module to effectively handle a subset of string queries having contextual metadata received from a client application in an instructional environment. The effectiveness of the training module can be based upon feedback from the client application. Upon completion of the training, a string analysis algorithm selection policy can be synthesized. The string analysis algorithm selection policy can correlate a context of a string query in the subset to the usage of a string analysis algorithm. When in the operational environment, the dynamic string analysis handler can dynamically handle string queries having contextual metadata received from the client application in accordance with the string analysis algorithm selection policy. The string analysis algorithm to be used for a string query can be dynamically and independently determined.
Detection of custom parameters in a request URL
Identifying at least one custom parameter in a request uniform resource locator (URL). At least a first portion of source code of a Web application that typically consumes the custom parameter provided in the request URL can be identified. The Web application can be instrumented at the first portion of the source code. The Web application can receive the request URL and the Web application can be executed with the instrumented source code. At least one run-time value consumed by the second portion of the source code can be identified, and the run-time value can be compared to the request URL to determine whether the run-time value intersects with the request URL. Responsive to determining that the run-time value intersects with the request URL, the run-time value can be identified as the custom parameter. A custom parameter rule can be generated based on the comparison.
Effective search-space pruning for solvers of string equations, regular expressions and length constraints
In recent years, string solvers have become an essential component in many formal-verification, security-analysis and bug-finding tools. Such solvers typically support a theory of string equations, the length function as well as the regular-expression membership predicate. These enable considerable expressive power, which comes at the cost of slow solving time, and in some cases even nontermination. We present two techniques, designed for word-based SMT string solvers, to mitigate these problems: (i) sound and complete detection of overlapping variables, which is essential to avoiding common cases of nontermination; and (ii) pruning of the search space via bi-directional integration between the string and integer theories, enabling new cross-domain heuristics. We have implemented both techniques atop the Z3-str solver, resulting in a significantly more robust and efficient solver, dubbed Z3str2, for the quantifier-free theory of string equations, the regular-expression membership predicate and linear arithmetic over the length function. We report on a series of experiments over four sets of challenging real-world benchmarks, where we compared Z3str2 with five different string solvers: S3, CVC4, Kaluza, PISA and Stranger. Each of these tools utilizes a different solving strategy and/or string representation (based e.g. on words, bit vectors or automata). The results point to the efficacy of our proposed techniques, which yield dramatic performance improvement. We argue that the techniques presented here are of broad applicability, and can be integrated into other SMT-backed string solvers to improve their performance.
Dynamic detection of inter-application communication vulnerabilities in Android
A main aspect of the Android platform is Inter-Application Communication (IAC), which enables reuse of functionality across apps and app components via message passing. While a powerful feature, IAC also constitutes a serious attack surface. A malicious app can embed a payload into an IAC message, thereby driving the recipient app into a potentially vulnerable behavior if the message is processed without its fields first being sanitized or validated. We present what to our knowledge is the first comprehensive testing algorithm for Android IAC vulnerabilities. Toward this end, we first describe a catalog, stemming from our field experience, of 8 concrete vulnerability types that can potentially arise due to unsafe handling of incoming IAC messages. We then explain the main challenges that automated discovery of Android IAC vulnerabilities entails, including in particular path coverage and custom data fields, and present simple yet surprisingly effective solutions to these challenges. We have realized our testing approach as the IntentDroid system, which is available as a commercial cloud service. IntentDroid utilizes lightweight platform-level instrumentation, implemented via debug breakpoints (to run atop any Android device without any setup or customization), to recover IAC-relevant app-level behaviors. Evaluation of IntentDroid over a set of 80 top-popular apps has revealed a total 150 IAC vulnerabilities  some already fixed by the developers following our report  with a recall rate of 92% w.r.t. a ground truth established via manual auditing by a security expert.
Global variable security analysis
A method includes determining selected global variables in a program for which flow of the selected global variables through the program is to be tracked. The selected global variables are less than all the global variables in the program. The method includes using a static analysis performed on the program, tracking flow through the program for the selected global variables. In response to one or more of the selected global variables being used in security-sensitive operations in the flow, use is analyzed of each one of the selected global variables in a corresponding security-sensitive operation. In response to a determination the use may be a potential security violation, the potential security violation is reported. Apparatus and computer program products are also disclosed.
Labyrinth: Visually Configurable Data-Leakage Detection in Mobile Applications
Mobile devices have revolutionized many aspects of our lives. We use smartphones and tablets as portable computers and, often without realizing it, we run various types of security-sensitive programs on them, such as personal and enterprise email and instant-messaging applications, as well as social, banking, insurance and retail programs. These applications access and transmit over the network numerous pieces of private information, including our geographical location, device ID, contacts, calendar events, passwords, and health records, as well as credit-card, social-security, and bank-account numbers. Guaranteeing that no private information is exposed to unauthorized observers is very challenging given the level of complexity that these applications have reached. Furthermore, using program-analysis tools with out-of-the-box configurations in order to detect confidentiality violations may not yield the desired results because only a few pieces of private data, such as the device's ID and geographical location, are obtained from standard sources. The majority of confidentiality sources (such as credit-card and bank-account numbers) are application-specific and require careful configuration. This paper presents Labyrinth, a run-time privacy enforcement system that automatically detects leakage of private data originating from standard as well as application-specific sources. Labyrinth features several novel contributions: (i) it allows for visually configuring, directly atop the application's User Interface (UI), the fields that constitute custom sources of private data, (ii) it does not require operating-system instrumentation, but relies only an application-level instrumentation and on a proxy that intercepts the communication between the mobile device and the back-end servers, and (iii) it performs an enhanced form of value-similarity analysis to detect data leakage even when sensitive data (such as a password) has been encoded or hashed. Labyrinth supports both Android and iOS. We have evaluated Labyrinth experimentally, and in this paper we report results on production-level applications.
Light: Replay via tightly bounded recording
Reproducing concurrency bugs is a prominent challenge. Existing techniques either rely on recording very fine grained execution information and hence have high runtime overhead, or strive to log as little information as possible but provide no guarantee in reproducing a bug. We present Light, a technique that features much lower overhead compared to techniques based on fine grained recording, and that guarantees to reproduce concurrent bugs. We leverage and formally prove that recording flow dependences is the necessary and sufficient condition to reproduce a concurrent bug. The flow dependences, together with the thread local orders that can be automatically inferred (and hence not logged), are encoded as scheduling constraints. An SMT solver is used to derive a replay schedule, which is guaranteed to exist even though it may be different from the original schedule. Our experiments show that Light has only 44% logging overhead, almost one order of magnitude lower than the state of the art techniques relying on logging memory accesses. Its space overhead is only 10% of those techniques. Light can also reproduce all the bugs we have collected whereas existing techniques miss some of them.
Application-and user-sensitive privacy enforcement in mobile systems
The mobile era is marked by exciting opportunities for utilization of contextual information in computing. Applications from different categories-including commercial and enterprise email, instant messaging, social, banking, insurance and retail-access, process and transmit over the network numerous pieces of sensitive information, such as the user's geographical location, device ID, contacts, calendar events, passwords, and health records, as well as credit-card, social-security, and bank-account numbers. Understanding and managing how an application handles private data is a significant challenge. There are not only multiple sources of such data (including primarily social accounts, user inputs and platform libraries), but also different release targets (such as advertising companies and application servers) and different forms of release (for example, passwords transmitted in the clear, hashed or encrypted). To the end users, and particularly those who are not tech savvy, it is nontrivial to manage these complexities. In response, we have designed Labyrinth, a system for privacy enforcement. The unique features of Labyrinth are (i) an intuitive visual interface for configuration of the privacy policy, which consists of enriched app screen captures annotated with privacy-related information, combined with (ii) a lightweight mechanism to detect and suppress privacy threats that is completely decoupled from the host platform. Labyrinth supports both Android and iOS. In this paper, we describe the Labyrinth architecture and illustrate its flow steps.
Correcting workflow security vulnerabilities via static analysis and virtual patching
A computer program can be statically analyzed to determine an order in which client side workflows are intended to be implemented by the computer program. A virtual patch can be generated. When executed by a processor, the virtual patch can track web service calls from a client to the computer program, and determine whether the order of the web service calls from the client to the computer program correlate to the order in which client side workflows are intended to be implemented by the computer program. If the order of the web service calls from the client to the computer program do not correlate to the order in which client side workflows are intended to be implemented by the computer program, an alert can be generated.
Detecting vulnerabilities in web applications
A method, computer program product, and system for detecting vulnerabilities in web applications is described. A method may comprise determining one or more values associated with a web application that flow to response data associated with the web application. The one or more values may be modifiable by unreliable input. The method may further comprise generating a representation of the response data associated with the web application. The method may additionally comprise determining one or more potentially vulnerable portions of the response data based upon, at least in part, the one or more values modifiable by the unreliable input that flow to the response data associated with the web application, and the representation of the response data associated with the web application.
Black-box testing of web applications with client-side code evaluation
A method, computer program product, and system for detecting vulnerabilities in web applications is described. A method may comprise determining one or more values associated with a web application that flow to response data associated with the web application. The one or more values may be modifiable by unreliable input. The method may further comprise generating a representation of the response data associated with the web application. The method may additionally comprise determining one or more potentially vulnerable portions of the response data based upon, at least in part, the one or more values modifiable by the unreliable input that flow to the response data associated with the web application, and the representation of the response data associated with the web application.
Generating a custom parameter rule based on a comparison of a run-time value to a request URL
Identifying at least one custom parameter in a request uniform resource locator (URL). The method can include identifying at least a first portion of source code of a Web application that typically consumes the custom parameter provided in the request URL and, via a processor, instrumenting the Web application at the first portion of the source code. The Web application can receive the request URL and the Web application can be executed with the instrumented source code. At least one run-time value consumed by the second portion of the source code can be identified, and the run-time value can be compared to the request URL to determine whether the run-time value intersects with the request URL. Responsive to determining that the run-time value intersects with the request URL, the run-time value can be identified as the custom parameter. A custom parameter rule can be generated based on the comparison.
Scalable and precise string analysis using index-sensitive static string abstractions
A disclosed method includes accessing one or more seeding specifications and a program including computer-readable code and applying the one or more seeding specifications to the program to identify for analysis seeds including strings for corresponding identified string variables. The method includes tracking flows emanating from the identified seeds. The tracking includes computing an integral offset into a tracked string variable for any statements causing such a computation. The tracking also includes providing a string representation based on the computed integral offset, wherein the provided string representation comprises a value of the integral offset and an indication of the corresponding tracked string variable. The tracking further includes modeling string manipulations of the tracked string variables using the string representations. Apparatus and program products are also disclosed.
Anomaly detection at the level of run time data structures
A useful embodiment of the invention is directed to a method associated with a computer program comprising one or more basic blocks, wherein the program defines and uses multiple data structures, such as the list of all customers of a bank along with their account information. The method includes identifying one or more invariants, wherein each invariant is associated with one of the data structures. The method further includes determining at specified times whether an invariant has been violated. Responsive to detecting a violation of one of the invariants, the detected violation is flagged as an anomaly.
Detecting multistep operations when interacting with web applications
Detecting multistep operations when interacting with web applications is performed by identifying a set of multiple web pages of a web application, where the web pages in the set of multiple web pages are sequentially navigable, identifying a group of multiple web page elements at the same relative location in each of the web pages in the set of multiple web pages, determining that the identified groups of web page elements are similar to each other in accordance with a predefined similarity criterion, identifying an element that is common to each identified group of web page elements, and determining that a characteristic of the element is uniquely varied in each of the identified groups of web page elements.
Detecting race condition vulnerabilities in computer software applications
Testing computer software applications is performed by identifying first and second executable portions of the computer software application, where the portions are configured to access a data resource, and where at least one of the portions is configured to write to the data resource, instrumenting the computer software application by inserting one or more instrumentation instructions into one or both of the portions, where the instrumentation instruction is configured to cause execution of the portion being instrumented to be extended by a randomly-determined amount of time, and testing the computer software application in multiple iterations, where the computer software application is executed in multiple parallel execution threads, where the portions are independently executed at least partially in parallel in different threads, and where the computer software application is differently instrumented in each of the iterations.
Crawling computer-based objects
Crawling computer-based objects is implemented by identifying a dependency between a first portion of a computer-based object set and a second portion of the computer-based object set, where the second portion is data-dependent on the first portion, and responsive to identifying the dependency, effecting a crawling of the first portion and thereafter a crawling of the second portion.
Identifying whether an application is malicious
Identifying whether a first application is malicious. The first application can be presented for installation on a processing system. The first application can be scanned, via a static analysis implemented by a processor, to determine whether a user interface layout of the first application is suspiciously similar to a user interface layout of a second application installed on the processing system. When the user interface layout of the first application is suspiciously similar to the user interface layout of the second application installed on the processing system, an alert can be generated indicating that the first application is malicious.
Enhanced string analysis that improves accuracy of static analysis
A method includes determining, as part of a static analysis of a program, links between functions in the program and performing, as part of the static analysis, string analysis on strings used in the program to determine additional links between the functions in the program. The method further includes outputting, as part of the static analysis, indications of at least the links between the functions and the additional links between the functions. Apparatus, computer programs, and program products are also disclosed.
Distributed static analysis of computer software applications
A method for distributed static analysis of computer software applications, includes: statically analyzing instructions of a computer software application; identifying at least one entry point in the computer software application; assigning a primary agent to statically analyze the computer software application from the entry point; assigning a secondary agent to statically analyze a call site encountered by the primary agent and produce a static analysis summary of the call site; and presenting results of any of the static analyzes via a computer-controlled output device.
Detecting security vulnerabilities in web applications
Method to detect security vulnerabilities includes: interacting with a web application during its execution to identify a web page exposed by the web application; statically analyzing the web page to identify a parameter within the web page that is constrained by a client-side validation measure and that is to be sent to the web application; determining a server-side validation measure to be applied to the parameter in view of the constraint placed upon the parameter by the client-side validation measure; statically analyzing the web application to identify a location within the web application where the parameter is input into the web application; determining whether the parameter is constrained by the server-side validation measure prior to the parameter being used in a security-sensitive operation; and identifying the parameter as a security vulnerability.
Refinement-based security analysis
A method, computer program product, and computer system for assigning, by a computing device, a value to a first data-flow of a first summary associated with a control flow graph and assigning the value to a second data-flow of a second summary associated with the control flow graph. The first data-flow with the value is identified to flow into a type of sink. The second data-flow with the value is identified not to flow into the type of sink. The first summary of a behavior of the first data-flow is refined in response to identifying that the first data-flow does flow into the type of sink. Refinement of the second summary of a behavior of the second data-flow is skipped in response to identifying that the second data-flow does not flow into the type of sink.
Transforming unit tests for security testing
A method, computer program product, and system for transforming unit tests is described. A unit test associated with one or more software units is identified. A first input parameter of the unit test is identified. A substitute parameter value is determined, wherein the substitute parameter value is associated with a security test for the one or more software units. A value of the first input parameter in the unit test is replaced with the substitute parameter value. The unit test including the substitute parameter value is implemented for the one or more software units. A first security issue associated with the one or more software units is identified, based upon, at least in part, replacing the first input parameter of the unit test with the substitute parameter value and implementing the unit test including the substitute parameter value.
Url tagging based on user behavior
A computerized method for tagging a resource locator based on user behavior statistics, comprising: collecting browsing data on at least one browsing action taken by each of a plurality of end users after browsing to a first web document, the first web document is referenced to by a resource locator in a second web document; analyzing, using a computerized processor, the browsing data to statistically identify a browsing characteristic of the first web document; and instructing the presentation of an indication of the browsing characteristic in association with the presentation of the second web document by a browser installed in a client terminal to a user browsing to the second web document.
Sound and effective data-flow analysis in the presence of aliasing
A method, an apparatus, and a computer program product are disclosed that include tracking, using a data flow model of a program suitable for taint analysis of the program, information from sources of taint to entities in a heap using a model of the heap based on the program. The tracking is performed so that the information is relevant for taint propagation and is performed in a manner that is field-sensitive for the entities in the heap. The method, apparatus, and computer program product also include, based on output of the tracking, the operation of performing data-flow analysis to determine taint flow from the sources of the taint through data flow paths to sinks using the taint.
Detecting persistent vulnerabilities in web applications
A method, including storing a test payload to a persistent state of an application and performing a static analysis to identify a first code location in the application that retrieves the test payload, to identify a first path from an entry point to the first code location, and to identify a second path from the first code location to a second code location that executes a security sensitive operation using the retrieved data. A dynamic analysis is then performed to retrieve the test payload via the first path, and to convey the test payload to the second code location via the second path.
Detecting persistent vulnerabilities in web applications
A method, including storing a test payload to a persistent state of an application and performing a static analysis to identify a first code location in the application that retrieves the test payload, to identify a first path from an entry point to the first code location, and to identify a second path from the first code location to a second code location that executes a security sensitive operation using the retrieved data. A dynamic analysis is then performed to retrieve the test payload via the first path, and to convey the test payload to the second code location via the second path.
Testing web services that are accessible via service oriented architecture (SOA) interceptors
Systems, methods, and computer program products are disclosed for testing web service-related elements, where the instructions of a web service-related element are statically analyzed to identify a characteristic of an output of the web service-related element, and where it is determined from a received response to a web service request that the web service request was processed by the web service-related element if at least a portion of the response matches the characteristic of the output of the web service-related element.
Weighted security analysis
A method, computer program product, and system for transforming unit tests is described. A unit test associated with one or more software units is identified. A graphical representation of a portion of a computer program is built, wherein the graphical representation includes a control flow edge. A potentially vulnerable data flow associated with the control flow edge is identified. A control flow weight is assigned to the control flow edge, based upon, at least in part, identifying the potentially vulnerable data flow. A security analysis is applied to the portion of the computer program based upon, at least in part, the control flow weight.
Application testing system and method
A method, computer program product, and computer system for sending, by a first computing device, a payload from a plurality of payloads to a second computing device. A response from the second computing device responding to the payload is received at the first computing device. It is determined whether the payload has successfully attacked an application executing at the second computing device based upon, at least in part, the response. If not, at least a portion of the plurality of payloads that shares a structural overlap with the first payload is identified. At least a second payload of the portion is prevented from being sent to the second computing device in response to identifying that the second payload shares the structural overlap with the first payload.
Certifying server side web applications against security vulnerabilities
Systems for server security verification include a report validation module configured to acquire a public key associated with a received report, where the received report was generated at a server, to decrypt the received report using the public key, and to determine a level of server-side security based on the decrypted report; and a processor configured to reconfigure a browser responsive to the determined level of server-side security.
Determining correctness conditions for use in static analysis
An embodiment comprising a method is associated with static analysis of a program, which detects violations of conditions of the program correctness specification. The method includes selectively encoding the program and adding one or more correctness conditions to the encoded program, wherein the added conditions comprise a set of assumptions that render the program correct with respect to one or more properties pertaining to detected violations. The set of assumptions are reported to a program user, together with a request to the user to verify the validity of each assumption of the set
Differential static program analysis
Systems for program analysis include a high-level scanning tool configured to perform a high-level analysis on a program using a processor to generate one or more high-level findings; one or more low-level scanning tools, each configured to perform a low-level analysis on the program using a processor to generate a low-level finding; and a mapping module configured to map the one or more low-level findings to the high-level findings to generate a concise combination report that categorizes each finding according to the highest-level analysis that produces the finding
Datacentric semantics for verification of privacy policy compliance by mobile applications
We introduce an enhanced information-flow analysis for tracking the amount of confidential data that is possibly released to third parties by a mobile application. The main novelty of our solution is that it can explicitly keep track of the footprint of data sources in the expressions formed and manipulated by the program, as well as of transformations over them, yielding a lazy approach with finer granularity, which may reduce false positives with respect to state-of-the-art information-flow analyses.
Access-rights Analysis in the Presence of Subjects
Modern software development and run-time environments, such as Java and the Microsoft .NET Common Language Runtime (CLR), have adopted a declarative form of access control. Permissions are granted to code providers, and during execution, the platform verifies compatibility between the permissions required by a security-sensitive operation and those granted to the executing code. While convenient, configuring the access-control policy of a program is not easy. If a code component is not granted sufficient permissions, authorization failures may occur. Thus, security administrators tend to define overly permissive policies, which violate the Principle of Least Privilege (PLP). A considerable body of research has been devoted to building program-analysis tools for computing the optimal policy for a program. However, Java and the CLR also allow executing code under the authority of a subject (user or service), and no program-analysis solution has addressed the challenges of determining the policy of a program in the presence of subjects. This paper introduces Subject Access Rights Analysis (SARA), a novel analysis algorithm for statically computing the permissions required by subjects at run time. We have applied SARA to 348 libraries in IBM WebSphere Application Server - a commercial enterprise application server written in Java that consists of >2 million lines of code and is required to support the Java permission- and subject-based security model. SARA detected 263 PLP violations, 219 cases of policies with missing permissions, and 29 bugs that led code to be unnecessarily executed under the authority of a subject. SARA corrected all these vulnerabilities automatically, and additionally synthesized fresh policies for all the libraries, with a false-positive rate of 5% and an average running time of 103 seconds per library. SARA also implements mechanisms for mitigating the risk of false negatives due to reflection and native code; according to a thorough result evaluation based on testing, no false negative was detected. SARA enabled IBM WebSphere Application Server to receive the Common Criteria for Information Technology Security Evaluation Assurance Level 4 certification.
Commutativity condition refinement
We present a technique for automatically generating commutativity conditions from (abstract-level) data-structure specifications. We observe that one can pose the commutativity question in a way that does not introduce additional quantifiers, via a mechanized lifting of a (potentially partial) specification to an equivalent total specification. We then describe an algorithm that iteratively refines an under-approximation of the commutativity (and non-commutativity) condition for two datastructure methods m and n into an increasingly precise version. Our algorithm terminates if/when the entire state space has been considered, and can be aborted at any time to obtain a partial, sound commutativity condition. We prove soundness, relative completeness, describe how to obtain input predicates, and discuss heuristics to improve qualitative aspects of our algorithms output. We have implemented our technique in a tool called SERVOIS, which uses an SMT solver. We show that we can automatically generate symbolic commutativity conditions for a range of data structures including Set, HashTable, Accumulator, Counter, and Stack. This work has the potential to impact a variety of contexts, in particular, multicore software where it has been realized that commutativity is at the heart of increased concurrency.
After-the-Fact Configuration of Static Analysis Tools Able to Reduce User Burden
A method includes mapping, based on a first mapping from possible security findings to possible configuration-related sources of imprecision, actual security findings from a static analysis of a program to corresponding configuration-related sources of imprecision, the mapping of the actual security findings creating a second mapping. A user is requested to configure selected ones of the configuration-related sources of imprecision from the second mapping. Responsive to a user updating configuration corresponding to the selected ones of the configuration-related sources of imprecision, security analysis results are updated for the static analysis of the program at least by determining whether one or more security findings from the security analysis results are no longer considered to be vulnerable based on the updated configuration by the user. The updated security analysis results are output. Apparatus and program products are also disclosed.
Optimizing Automated Interactions with Web Applications
Optimizing automated interactions with web pages by identifying, for each of multiple web pages, path information including an incoming hyperlink path having at least one hyperlink, where the incoming hyperlink path leads to the web page, and/or an outgoing hyperlink path having at least one hyperlink, where the outgoing hyperlink path emanates from the web page, determining whether the path information of each of the web pages meets a similarity condition, excluding from an interaction set of the web pages any of the web pages whose path information meets the similarity condition, and causing an automated interaction to be performed with any of the web pages in the interaction set.
Optimizing Automated Interactions with Web Applications
Optimizing automated interactions with web pages by identifying, for each of multiple web pages, path information including an incoming hyperlink path having at least one hyperlink, where the incoming hyperlink path leads to the web page, and/or an outgoing hyperlink path having at least one hyperlink, where the outgoing hyperlink path emanates from the web page, determining whether the path information of each of the web pages meets a similarity condition, excluding from an interaction set of the web pages any of the web pages whose path information meets the similarity condition, and causing an automated interaction to be performed with any of the web pages in the interaction set.
Detecting security vulnerabilities on computing devices
Optimizing automated interactions with web pages by identifying, for each of multiple web pages, path information including an incoming hyperlink path having at least one hyperlink, where the incoming hyperlink path leads to the web page, and/or an outgoing hyperlink path having at least one hyperlink, where the outgoing hyperlink path emanates from the web page, determining whether the path information of each of the web pages meets a similarity condition, excluding from an interaction set of the web pages any of the web pages whose path information meets the similarity condition, and causing an automated interaction to be performed with any of the web pages in the interaction set.
Determining the vulnerability of computer software applications to privilege-escalation attacks
Determining the vulnerability of computer software applications to privilege-escalation attacks, such as where an instruction classifier is configured to be used for identifying a candidate access-restricted area of the instructions of a computer software application, and a static analyzer is configured to statically analyze the candidate access-restricted area to determine if there is a conditional instruction that controls execution flow into the candidate access-restricted area, perform static analysis to determine if the conditional instruction is dependent on a data source within the computer software application, and designate the candidate access-restricted area as vulnerable to privilege-escalation attacks absent either of the conditional instruction and the date source.
Interactive analysis of a security specification
Analyzing a security specification. An embodiment can include identifying a downgrader in a computer program under test. Testing on the downgrader can be performed in a first level of analysis. Responsive to the downgrader not passing the testing performed in the first level of analysis, a counter example for the downgrader can be automatically synthesized. Further, a test unit can be created for the downgrader using the counter example as an input parameter to the downgrader. The test unit can be executed to perform testing on the downgrader in a second level of analysis. Responsive to the downgrader passing the testing performed in the second level of analysis, a user can be prompted to simplify a model of the downgrader.
Dynamic concolic execution of an application
Dynamic concolic execution of an application. A first hypotheses pertaining to a nature of test payloads that satisfy a specified property, and that are expected to satisfy a condition tested by the application's program code, can be generated. A plurality of first test payloads to test first hypothesis can be synthesized and submitted to the application during respective executions of the application. Whether each of the first test payloads actually satisfy the condition tested by the application's program code can be determined. When at least one of the first test payloads does not actually satisfy the condition tested by the application's program code, a second hypotheses that is expected to satisfy the condition tested by the application's program code can be generated. A plurality of second test payloads to test the second hypothesis can be synthesized and submitted to the application during respective executions of the application.
Black-box testing of web applications with client-side code evaluation
Detecting security vulnerabilities in web applications by interacting with a web application at a computer server during its execution at the computer server, identifying client-side instructions provided by the web application responsive to an interaction with the web application, where the client-side instructions are configured to be implemented by a client computer that receives the client-side instructions from the computer server, evaluating the identified client-side instructions, and identifying a security vulnerability associated with the client-side instructions.
Determining the vulnerability of computer software applications to privilege-escalation attacks
Determining the vulnerability of computer software applications to privilege-escalation attacks, such as where an instruction classifier is configured to be used for identifying a candidate access-restricted area of the instructions of a computer software application, and a static analyzer is configured to statically analyze the candidate access-restricted area to determine if there is a conditional instruction that controls execution flow into the candidate access-restricted area, perform static analysis to determine if the conditional instruction is dependent on a data source within the computer software application, and designate the candidate access-restricted area as vulnerable to privilege-escalation attacks absent either of the conditional instruction and the date source.
Discovery of application vulnerabilities involving multiple execution flows
Methods and systems for security analysis of an application are disclosed. One system includes a flow-insensitive analyzer, a control flow assessment module and a flow-sensitive analyzer. The flow-insensitive analyzer is configured to conduct a flow-insensitive analysis on the application to obtain a set of potential vulnerabilities in the application. In addition, the control flow assessment module is configured to determine, for each of the potential vulnerabilities, a relevant set of control flows that include the respective vulnerability. Further, the flow-sensitive analyzer is configured to perform, by a hardware processor, for each relevant set of control flows, a flow-sensitive analysis of at least one of the control flows in the corresponding relevant set to assess the validity of the respective vulnerability.
String analysis based on three-valued logic
Performing string analysis based on three-valued logic by including expressing a property of a string in a computer software application as a three-valued logic shape predicate, performing a three-valued logic shape analysis using the shape predicate to reach a fixpoint solution, and evaluating the fixpoint solution to determine a three-valued logic value of the property.
Hybrid dependency analysis using dynamic and static analyses
A method, computer program product, and system for performing a hybrid dependency analysis is described. According to an embodiment, a method may include computing, by one or more computing devices, one or more dynamic hints based on a finite set of executions of a computer program. The method may further include performing, by the one or more computing devices, a hybrid dependence analysis of one or more statements of the computer program.
Grail: context-aware fixing of concurrency bugs
Writing efficient synchronization for multithreaded programs is notoriously hard. The resulting code often contains subtle concurrency bugs. Even worse, many bug fixes introduce new bugs. A classic example, seen widely in practice, is deadlocks resulting from fixing of an atomicity violation. These complexities have motivated the development of automated fixing techniques. Current techniques generate fixes that are typically conservative, giving up on available parallelism. Moreover, some of the techniques cannot guarantee the correctness of a fix, and may introduce deadlocks similarly to manual fix, whereas techniques that ensure correctness do so at the expense of even greater performance loss. We present Grail, a novel fixing algorithm that departs from previous techniques by simultaneously providing both correctness and optimality guarantees. Grail synthesizes bug-free yet optimal lock-based synchronization. To achieve this, Grail builds an analysis model of the buggy code that is both contextual, distinguishing different aliasing contexts to ensure efficiency, and global, accounting for the entire synchronization behavior of the involved threads to ensure correctness. Evaluation of Grail on 12 bugs from popular codebases confirms its practical advantages, especially compared with existing techniques: Grail patches are, in general, >=40% more efficient than the patches produced by other techniques, and incur only 2% overhead.
Aletheia: Improving the usability of static security analysis
The scale and complexity of modern software systems complicate manual security auditing. Automated analysis tools are gradually becoming a necessity. Specifically, static security analyses carry the promise of efficiently verifying large code bases. Yet, a critical usability barrier, hindering the adoption of static security analysis by developers, is the excess of false reports. Current tools do not offer the user any direct means of customizing or cleansing the report. The user is thus left to review hundreds, if not thousands, of potential warnings, and classify them as either actionable or spurious. This is both burdensome and error prone, leaving developers disenchanted by static security checkers. We address this challenge by introducing a general technique to refine the output of static security checkers. The key idea is to apply statistical learning to the warnings output by the analysis based on user feedback on a small set of warnings. This leads to an interactive solution, whereby the user classifies a small fragment of the issues reported by the analysis, and the learning algorithm then classifies the remaining warnings automatically. An important aspect of our solution is that it is user centric. The user can express different classification policies, ranging from strong bias toward elimination of false warnings to strong bias toward preservation of true warnings, which our filtering system then executes. We have implemented our approach as the Aletheia tool. Our evaluation of Aletheia on a diversified set of nearly 4,000 client-side JavaScript benchmarks, extracted from 675 popular Web sites, is highly encouraging. As an example, based only on 200 classified warnings, and with a policy biased toward preservation of true warnings, Aletheia is able to boost precision by a threefold factor (x 2.868), while reducing recall by a negligible factor (x 1.006). Other policies are enforced with a similarly high level of efficacy.
Interactive analysis of a security specification
Analyzing a security specification. An embodiment can include identifying a downgrader in a computer program under test. Via a processor, testing on the downgrader can be performed in a first level of analysis. Responsive to the downgrader not passing the testing performed in the first level of analysis, a counter example for the downgrader can be automatically synthesized. Further, a test unit can be created for the downgrader using the counter example as an input parameter to the downgrader. The test unit can be executed to perform testing on the downgrader in a second level of analysis. Responsive to the downgrader passing the testing performed in the second level of analysis, a user can be prompted to simplify a model of the downgrader.
Hybrid analysis of vulnerable information flows
Arrangements described herein relate to analyzing vulnerable information flows in an application. A black-box scan of the application can be performed to record a call-tree representation of call stacks arising in the application due to test inputs provided during the black-box scan. For each path in the call-tree representation that does not constitute a vulnerable information flow during the black-box scan, a static analysis can be performed to determine at least one parameter value that, when abstracted, drives execution of the application, via the path, to flow to the at least one security sink. A security report can be generated identifying at least one of the paths in the call-tree representation that does not constitute the vulnerable information flow during the black-box scan, but flows to the at least one security sink when the at least one parameter value is abstracted.
Identifying whether an application is malicious
Identifying whether a first application is malicious. The first application can be presented for installation on a processing system. The first application can be scanned, via a static analysis implemented by a processor, to determine whether a user interface layout of the first application is suspiciously similar to a user interface layout of a second application installed on the processing system. When the user interface layout of the first application is suspiciously similar to the user interface layout of the second application installed on the processing system, an alert can be generated indicating that the first application is malicious.
Integrating Security, Analytics and Application Management into the Mobile Development Lifecycle
The advent of mobile devices has revolutionized many aspects of the software lifecycle. Unlike Web applications, which delegate most of the business logic to the server and use the client side for the presentation logic, mobile apps are client intensive. Another crucial difference is that the client side of Web applications is typically written using a combination of platform-independent Web languages, whereas most mobile apps have native clients written in platform-specific languages. Though nativity hinders the portability of mobile apps across different platforms and even different devices inside the same platform, it enables smooth high-fidelity experience, high performance and compliance with the platform's UI style---requirements that can only be satisfied natively. The main cost, beyond the initial coding of a mobile app, is to maintain its different variants in the presence of updates. Indeed, mobile code is typically updated frequently, with bug fixes and new features integrated into each new version. In the enterprise setting, these new features often revolve around security, analytics and Mobile App Management (MAM). This paper presents Enceladus, an app-level instrumentation framework that addresses these high-maintenance costs by transparently enriching any mobile enterprise app with new analytics, security and MAM capabilities not otherwise present in the original app source code. With Enceladus, the mobile app lifecycle is significantly reduced because the instrumentation is visually configurable, and any change to the instrumentation policy can be pushed transparently without requiring a full app update.
Flint: fixing linearizability violations
Writing concurrent software while achieving both correctness and efficiency is a grand challenge. To facilitate this task, concurrent data structures have been introduced into the standard library of popular languages like Java and C#. Unfortunately, while the operations exposed by concurrent data structures are atomic (or linearizable), compositions of these operations are not necessarily atomic. Recent studies have found many erroneous implementations of composed concurrent operations. We address the problem of fixing nonlinearizable composed operations such that they behave atomically. We introduce Flint, an automated fixing algorithm for composed Map operations. Flint accepts as input a composed operation suffering from atomicity violations. Its output, if fixing succeeds, is a composed operation that behaves equivalently to the original operation in sequential runs and is guaranteed to be atomic. To our knowledge, Flint is the first general algorithm for fixing incorrect concurrent compositions. We have evaluated Flint on 48 incorrect compositions from 27 popular applications, including Tomcat and MyFaces. The results are highly encouraging: Flint is able to correct 96% of the methods, and the fixed version is often the same as the fix by an expert programmer and as efficient as the original code.
Interactive analysis of a security specification
Analyzing a security specification. An embodiment can include identifying a downgrader in a computer program under test. Testing on the downgrader can be performed in a first level of analysis. Responsive to the downgrader not passing the testing performed in the first level of analysis, a counter example for the downgrader can be automatically synthesized. Further, a test unit can be created for the downgrader using the counter example as an input parameter to the downgrader. The test unit can be executed to perform testing on the downgrader in a second level of analysis. Responsive to the downgrader passing the testing performed in the second level of analysis, a user can be prompted to simplify a model of the downgrader.
Automatic synthesis of unit tests for security testing
Performing security analysis on a computer program under test (CPUT). The CPUT can be analyzed to identify data pertinent to potential security vulnerabilities of the CPUT. At least a first unit test configured to test a particular unit of program code within the CPUT can be automatically synthesized. The first unit test can be configured to initialize at least one parameter used by the particular unit of program code within the CPUT, and can be provided at least a first test payload configured to exploit at least one potential security vulnerability of the CPUT. The first unit test can be dynamically processed to communicate the first test payload to the particular unit of program code within the CPUT. Whether the first test payload exploits an actual security vulnerability of the CPUT can be determined, and a security analysis report can be output.
Distributed static analysis of computer software applications
A method for distributed static analysis of computer software applications, includes: statically analyzing instructions of a computer software application; identifying at least one entry point in the computer software application; assigning a primary agent to statically analyze the computer software application from the entry point; assigning a secondary agent to statically analyze a call site encountered by the primary agent and produce a static analysis summary of the call site; and presenting results of any of the static analyses via a computer-controlled output device.
Training classifiers for program analysis
Methods for training a static security analysis classifier include running an initial security analysis on a training codebase to generate a set of vulnerabilities associated with the training codebase; analyzing the program with a feature set that limits a number of detected vulnerabilities to generate a limited set of vulnerabilities associated with the feature set; comparing the limited set of vulnerabilities to a known vulnerability distribution to generate an accuracy score; and iterating the steps of analyzing and comparing using different feature sets to find a feature set having a highest accuracy score.
Generating sound and minimal security reports based on static analysis of a program
A method is disclosed that includes, using a static analysis, analyzing a software program to determine a number of paths from sources accepting information to sinks using that information or a modified version of that information and to determine multiple paths from the number of paths. The determined multiple paths have a same transition from an application portion of the software program to a library portion of the software program and require a same downgrading action to address a vulnerability associated with source-sink pairs in the multiple paths. The analyzing includes determining the multiple paths using a path-sensitive analysis. The method includes, for the determined multiple paths, grouping the determined multiple paths into a single representative indication of the determined multiple paths. The method includes outputting the single representative indication. Computer program products and apparatus are also disclosed.
Method and apparatus for paralleling and distributing static source code security analysis using loose synchronization
A method of static source code analysis is provided. A forward search of source code is performed from each of a plurality of source nodes. A backward search of source code is performed from each of a plurality of sink nodes, wherein the forward search and the backward search are performed in parallel simultaneously. The progress of the forward search and the backward search are monitored to determine if the searches intersect at a common node. A vulnerability alert is generated when the monitoring determines that a forward search and a backward search reach a common node.
Effective testing of authorization logic of web components which utilize claims-based authorization
An authorization algorithm of a software component can be selected. A static code analysis can be performed to determine a conditional statement within an algorithm of the software component. The outcome of the conditional statement can be established based on an input and a criteria using dynamic code analysis. The input can be a value associated with a claim set of a claims-based authentication policy. The criteria can be an authentication criteria specified within the algorithm. Responsive to the outcome, an execution path associated with the outcome can be determined and a code coverage criterion can be met for the conditional statement.
Effective testing of authorization logic of web components which utilize claims-based authorization
An authorization algorithm of a software component can be selected. A static code analysis can be performed to determine a conditional statement within an algorithm of the software component. The outcome of the conditional statement can be established based on an input and a criteria using dynamic code analysis. The input can be a value associated with a claim set of a claims-based authentication policy. The criteria can be an authentication criteria specified within the algorithm. Responsive to the outcome, an execution path associated with the outcome can be determined and a code coverage criterion can be met for the conditional statement.
Selective data flow analysis of bounded regions of computer software applications
Performing data flow analysis of a computer software application, including, for a data flow analysis type, identifying within a computer software application code base a plurality of seeds relating to the data flow analysis type, for each of the plurality of seeds, defining a portion of the computer software application code base to a predefined depth of calls backward from the seed and to a predefined depth of calls forward from the seed, thereby resulting in a plurality of bounded portions of the computer software application code base, detecting a change in the computer software application code base, and performing, on any of the bounded portions affected by the change, a data flow analysis relating to the data flow analysis type.
Fixing security vulnerability in a source code
A computer implemented method for automatically fixing a security vulnerability in a source code. The method includes obtaining identification of a code block that includes a code that sends tainted data to a corresponding sink code in the source code and automatically fixing the vulnerability by automatically performing code modification which is selected from the group of code modifications consisting of: code motion and code duplication.
Rule Matching In The Presence Of Languages With No Types Or As An Adjunct To Current Analyses For Security Vulnerability Analysis
A method includes reading by a computing system a rule file including one or more rules having specified paths to methods, each method corresponding to one of a sink, source, or sanitizer. The method includes matching by the computing system the methods to corresponding ones of sinks, sources, or sanitizers determined through a static analysis of an application. The static analysis determines at least flows from sources of information to sinks that use the information. The method includes performing by the computing system, using the sinks, sources, and sanitizers found by the matching, a taint analysis to determine at least tainted flows from sources to sinks, wherein the tainted flows are flows passing information to sinks without the information being endorsed by a sanitizer. Apparatus and program products are also disclosed.
A Bayesian Approach to Privacy Enforcement in Smartphones.
Mobile apps often require access to private data, such as the device ID or location. At the same time, popular platforms like Android and iOS have limited support for user privacy. This frequently leads to unauthorized disclosure of private information by mobile apps, e.g. for advertising and analytics purposes. This paper addresses the problem of privacy enforcement in mobile systems, which we formulate as a classification problem: When arriving at a privacy sink (e.g., database update or outgoing web message), the runtime system must classify the sinks behavior as either legitimate or illegitimate. The traditional approach of information-flow (or taint) tracking applies binary classification, whereby information release is legitimate iff there is no data flow from a privacy source to sink arguments. While this is a useful heuristic, it also leads to false alarms. We propose to address privacy enforcement as a learning problem, relaxing binary judgments into a quantitative/probabilistic mode of reasoning. Specifically, we propose a Bayesian notion of statistical classification, which conditions the judgment whether a release point is legitimate on the evidence arising at that point. In our concrete approach, implemented as the BAYESDROID system that is soon to be featured in a commercial product, the evidence refers to the similarity between the data values about to be released and the private data stored on the device. Compared to TaintDroid, a state-of-the-art taint-based tool for privacy enforcement, BAYESDROID is substantially more accurate. Applied to 54 top-popular Google Play apps, BAYESDROID is able to detect 27 privacy violations with only 1 false alarm.
Automatic classification of security vulnerabilities in computer software applications
Automatically classifying security vulnerabilities in computer software applications by identifying candidate security vulnerabilities in a learning set including at least a first computer software application, classifying each of the candidate security vulnerabilities using predefined classifications, determining, for each of the candidate security vulnerabilities, values for predefined properties, creating a set of correlations between the property values and the classifications of the candidate security vulnerabilities, identifying a candidate security vulnerability in a second computer software application, determining, for the candidate security vulnerability in the second computer software application, values for the predefined properties, and using the set of correlations to classify the candidate security vulnerability in the second computer software application with a classification from the predefined classifications that best correlates with the property values of the candidate security vulnerability in the second computer software application.
Static analysis of computer software applications
Static analysis of a computer software application can be performed by applying a first level of abstraction to model a plurality of run-time objects, thereby producing a set of object abstractions. Static data-flow analysis of the computer software application can be performed using the set of object abstractions, thereby producing a first data-flow propagation graph. A data-flow bottleneck can be identified within the data-flow propagation graph. A second level of abstraction can be applied to model any of the run-time objects having in the set of object abstractions a corresponding object abstraction that is traceable to the data-flow bottleneck. The applying the second level of abstraction can decompose the corresponding object abstraction into a set of object abstractions, thereby modifying the set of object abstractions. Static data-flow analysis of the computer software application can be performed using the modified set of object abstractions.
Static analysis for verification of software program access to secure resources for computer systems
Computer program products and apparatus are disclosed. Using a static analysis, a software program is analyzed to determine whether the software program accesses a secure resource for a computer system without verification that the secure resource can be accessed by the software program. In response to an access by the software program to the secure resource without verification that the secure resource can be accessed by the software program, a result is output indicative of the analyzing. An apparatus is disclosed that includes a user interface providing a security report to a user, the security report indicating a result of an analysis of whether or not a software program accesses a secure resource for a computer system without verification that the secure resource can be accessed by the software program.
Mitigating security risks via code movement
A method includes performing on a computing system a source-to-sink reachability analysis of code of an application. The reachability analysis is performed using a static analysis of the code and determines flows from sources of information to sinks that use the information. The method includes determining scopes for corresponding security sensitive operations using the determined flows, each of the security sensitive operations corresponding to statements in the code and one or more flows. A scope for a security sensitive operation includes a block of statements in the code that correspond to a set of one or more flows ending at a sink. The method includes, for each of one or more selected scopes, moving statements in a corresponding block of statements that are independent of a security sensitive operation in the block to code before or after the block. Apparatus and program products are also disclosed.
Hybrid security analysis of web javascript code via dynamic partial evaluation
This paper addresses the problem of detecting JavaScript security vulnerabilities in the client side of Web applications. Such vulnerabilities are becoming a source of growing concern due to the rapid migration of server-side business logic to the client side, combined with new JavaScript-backed Web technologies, such as AJAX and HTML5. Detection of client-side vulnerabilities is challenging given the dynamic and event-driven nature of JavaScript. We present a hybrid form of JavaScript analysis, which augments static analysis with (semi-)concrete information by applying partial evaluation to JavaScript functions according to dynamic data recorded by the Web crawler. The dynamic component rewrites the program per the enclosing HTML environment, and the static component then explores all possible behaviors of the partially evaluated program (while treating user-controlled aspects of the environment conservatively). We have implemented this hybrid architecture as the JSA analysis tool, which is integrated into the IBM AppScan Standard Edition product. We formalize the static analysis and prove useful properties over it. We also tested the system across a set of 170,000 Web pages, comparing it with purely static and dynamic alternatives. The results provide conclusive evidence in favor of our hybrid approach. Only 10% of the reports by JSA are false alarms compared to 63% of the alarms flagged by its purely static counterpart, while not a single true warning is lost. This represents a reduction of 94% in false alarms. Compared with a commercial testing algorithm, JSA detects vulnerabilities in >4x more Web sites with only 4 false alarms.
Web services
A method, system, and/or computer program product invokes a web service in a software application. A software application comprises a machine readable description of a functionality to be supported by a web service to be invoked, and a machine readable description of an execution instruction for the web service to be invoked. One or more processors determine/identify a web service that supports the functionality to be supported and the execution instruction for the web service to be invoked.
Automated detection of flaws and incompatibility problems in information flow downgraders
Mechanisms for evaluating downgrader code in application code with regard to a target deployment environment. Downgrader code in the application code is identified. Based on an input string, an output string that the downgrader code outputs in response to receiving the input string is identified. One or more sets of illegal string patterns are retrieved. Each of the one or more sets of illegal string patterns is associated with a corresponding deployment environment. The illegal string patterns are string patterns that a downgrader identifies in the information flow for security purposes. A determination is made as to whether the downgrader code is compatible with the target deployment environment based on the one or more sets of illegal string patterns and the output string. An output indicative of the results of the determining is generated.
Static analysis of computer software applications
Static analysis of a computer software application can be performed by applying a first level of abstraction to model a plurality of run-time objects, thereby producing a set of object abstractions. Static data-flow analysis of the computer software application can be performed using the set of object abstractions, thereby producing a first data-flow propagation graph. A data-flow bottleneck can be identified within the data-flow propagation graph. A second level of abstraction can be applied to model any of the run-time objects having in the set of object abstractions a corresponding object abstraction that is traceable to the data-flow bottleneck. The applying the second level of abstraction can decompose the corresponding object abstraction into a set of object abstractions, thereby modifying the set of object abstractions. Static data-flow analysis of the computer software application can be performed using the modified set of object abstractions.
Using a heuristically-generated policy to dynamically select string analysis algorithms for client queries
A method for dynamically selecting string analysis algorithms can begin with the training of the dynamic string analysis handler of a string analysis module to effectively handle a subset of string queries having contextual metadata received from a client application in an instructional environment. The effectiveness of the training module can be based upon feedback from the client application. Upon completion of the training, a string analysis algorithm selection policy can be synthesized. The string analysis algorithm selection policy can correlate a context of a string query in the subset to the usage of a string analysis algorithm. When in the operational environment, the dynamic string analysis handler can dynamically handle string queries having contextual metadata received from the client application in accordance with the string analysis algorithm selection policy. The string analysis algorithm to be used for a string query can be dynamically and independently determined.
Efficient code instrumentation
A method for instrumenting a computer program, the method including identifying a program slice within a computer program, and instrumenting the program slice within the program.
Discovery of application vulnerabilities involving multiple execution flows
Methods and systems for security analysis of an application are disclosed. In accordance with one method, a flow-insensitive analysis is conducted on the application to obtain a set of potential vulnerabilities in the application. For each of the potential vulnerabilities, a relevant set of control flows that include the respective vulnerability is determined. Further, for each relevant set of control flows, a flow-sensitive analysis of at least one of the control flows in the corresponding relevant set is performed by a hardware processor to assess the validity of the respective vulnerability.
Detecting security vulnerabilities on computing devices
Identifying security vulnerabilities on computing devices by detecting an inter-process communication on a computing device, determining whether the inter-process communication is consistent with a predefined specification of a security vulnerability, and causing a predefined action to be performed on the computing device responsive to determining that the inter-process communication is consistent with a predefined specification of a security vulnerability.
Eliminating false-positive reports resulting from static analysis of computer software
A system for eliminating false-positive reports resulting from static analysis of computer software is provided herein. The system includes the following components executed by a processor: a modeler configured to model a computer code into a model that defines sources, sinks, and flows; a static analyzer configured to apply static analysis to the code or the model, to yield reports indicative of at least one issue relating to one or more of the flows; a preconditions generator configured to generate preconditions for eliminating false-positive issues in the reports, based on the model and user-provided input; and a preconditions checker configured to apply the generated preconditions to the reports for eliminating false-positive issues in the reports.
Static analysis of validator routines
A method includes accessing a validator routine having an input string and one or more return points, each return point returning a return value having two possible values; finding the return points in the validator routine; for each of the return points, performing a backwards traversal from a return point through a code section and determining constraints on the input string based at least on one or both of the two possible return values for the return point; using the determined constraints for the input string, determining whether all of the return values returned from the one or more return points meet validation constraints; and outputting one or more indications of whether all of the returned values returned from the return points meet the validation constraints for the one or both of the two possible return values. Apparatus and computer program products are also disclosed.
Static analysis of computer software applications having a model-view-controller architecture
Preparing a computer software application for static analysis by identifying a control flow within a model portion of a computer software application having a model-view-controller architecture, where the control flow passes a value to a controller portion of the computer software application, analyzing a declarative specification of the controller portion of the computer software application to identify a view to which the controller portion passes control based on the value, and synthesizing a method within the computer software application, where the method calls the view.
Collaborative application testing
A method, computer program product, and computer system for performing, at a computing device, an analysis of a web application. A response is annotated by the web application with coverage data based upon, at least in part, the analysis, wherein the coverage data indicates which actions have been performed on the web application and which actions have not been performed on the web application according to results of the analysis. The response that includes the coverage data is shared with one or more users.
Hybrid Program Analysis
A hybrid program analysis method includes initiating a static program analysis of an application, generating, by a static program analyzer, a query to a dynamic program analyzer upon determining a code construct of the application requiring dynamic analysis, resolving, by the dynamic program analyzer, the query into a set of arguments with which to invoke the code construct of the application, generating, by the dynamic program analyzer, the set of arguments, invoking, by the dynamic program analyzer, the code construct of the application using set of arguments, answering, by the dynamic program analyzer, the query, and continuing the static program analysis of the application.
Differential static program analysis
Methods for program analysis include performing a high-level analysis on a program using a processor to generate one or more high-level findings; performing one or more low-level analyses on the program using a processor to generate one or more low-level findings; mapping the one or more low-level findings to the high-level findings to generate a concise combination report that categorizes each finding according to the highest-level analysis that produces the finding.
Detecting security vulnerabilities in web applications
Method to detect security vulnerabilities includes: interacting with a web application during its execution to identify a web page exposed by the web application; statically analyzing the web page to identify a parameter within the web page that is constrained by a client-side validation measure and that is to be sent to the web application; determining a server-side validation measure to be applied to the parameter in view of the constraint placed upon the parameter by the client-side validation measure; statically analyzing the web application to identify a location within the web application where the parameter is input into the web application; determining whether the parameter is constrained by the server-side validation measure prior to the parameter being used in a security-sensitive operation; and identifying the parameter as a security vulnerability.
Method and apparatus for paralleling and distributing static source code security analysis using loose synchronization
A method of static source code analysis is provided. A forward search of source code is performed from each of a plurality of source nodes. A backward search of source code is performed from each of a plurality of sink nodes, wherein the forward search and the backward search are performed in parallel simultaneously. The progress of the forward search and the backward search are monitored to determine if the searches intersect at a common node. A vulnerability alert is generated when the monitoring determines that a forward search and a backward search reach a common node.
Detection of DOM-based cross-site scripting vulnerabilities
Testing a Web-based application for security vulnerabilities. At least one client request including a payload having a unique identifier can be communicated to the Web-based application. Response HTML and an associated Document Object Model (DOM) object can be received from the Web-based application. Content corresponding to the payload can be identified in the DOM object via the unique identifier. A section of the DOM object including the payload can be identified as un-trusted.
Static analysis for verification of software program access to secure resources for computer systems
Computer program products and apparatus are disclosed. Using a static analysis, a software program is analyzed to determine whether the software program accesses a secure resource for a computer system without verification that the secure resource can be accessed by the software program. In response to an access by the software program to the secure resource without verification that the secure resource can be accessed by the software program, a result is output indicative of the analyzing. An apparatus is disclosed that includes a user interface providing a security report to a user, the security report indicating a result of an analysis of whether or not a software program accesses a secure resource for a computer system without verification that the secure resource can be accessed by the software program.
Mining attack vectors for black-box security testing
Black-box security testing for a Web application includes identifying infrastructure supporting the Web application, obtaining vulnerability data for the Web application from an external data source according to the infrastructure, deriving a test payload from the vulnerability data using a processor, and determining a type of vulnerability exploited by the test payload. An existing validation operation of a testing system is selected for validating a response from the Web application to the test payload according to the type of vulnerability.
Selective data flow analysis of bounded regions of computer software applications
Performing data flow analysis of a computer software application, including, for a data flow analysis type, identifying within a computer software application code base a plurality of seeds relating to the data flow analysis type, for each of the plurality of seeds, defining a portion of the computer software application code base to a predefined depth of calls backward from the seed and to a predefined depth of calls forward from the seed, thereby resulting in a plurality of bounded portions of the computer software application code base, detecting a change in the computer software application code base, and performing, on any of the bounded portions affected by the change, a data flow analysis relating to the data flow analysis type.
Formal analysis of the quality and conformance of information flow downgraders
Mechanisms for evaluating downgrader code in application code with regard to one or more security guidelines are provided. Downgrader code in application code is identified, where the downgrader code is a portion of code in the application code that operates on an information flow of the application code to ensure confidentiality of information input to the downgrader code, in the output of the downgrader code. Processes of the downgrader code are evaluated against security guidelines to determine if the processes violate the security guidelines. A notification is generated in response to the evaluation indicating that the processes of the downgrader code violate the security guidelines. The notification is output to a computing device for consideration.
Determining correctness conditions for use in static analysis
An embodiment comprising a method is associated with static analysis of a program, which detects violations of conditions of the program correctness specification. The method includes selectively encoding the program and adding one or more correctness conditions to the encoded program, wherein the added conditions comprise a set of assumptions that render the program correct with respect to one or more properties pertaining to detected violations. The set of assumptions are reported to a program user, together with a request to the user to verify the validity of each assumption of the set.
Anomaly detection at the level of run time data structures
A useful embodiment of the invention is directed to a method associated with a computer program comprising one or more basic blocks, wherein the program defines and uses multiple data structures, such as the list of all customers of a bank along with their account information. The method includes identifying one or more invariants, wherein each invariant is associated with one of the data structures. The method further includes determining at specified times whether an invariant has been violated. Responsive to detecting a violation of one of the invariants, the detected violation is flagged as an anomaly.
Static analysis based on observed string values during execution of a computer-based software application
Improving static analysis precision by recording a value pointed to by a string variable within the computer-based software application during the execution of a computer-based software application, modeling an invariant based on the recorded value, where the invariant represents at least one possible value pointed to by the string variable, performing a first static analysis of the computer-based software application to determine whether the invariant is valid with respect to the computer-based software application, and seeding a second static analysis of the computer-based software application with the invariant if the invariant is valid with respect to the computer-based software application.
Runtime enforcement of security checks
A method is disclosed that includes tracking untrusted inputs through an executing program into a sink, the tracking including maintaining context of the sink as strings based on the untrusted inputs flow into the sink. The method also includes, while tracking, in response to a string based on an untrusted input being about to flow into the sink and a determination the string could lead to an attack if the string flows into a current context of the sink, endorsing the string using an endorser selected based at least on the current context of the sink, and providing the endorsed string to the sink. Computer program products and apparatus are also disclosed.
Answering security queries statically based on dynamically-determined information
A method includes analyzing execution of a software program, the software program having sources returning values, sinks that perform security-sensitive operations on those returned values or modified versions of the returned values, and flows of the returned values to the sinks, the analyzing determining a first set of methods having access to a value returned from a selected one of the sources. A static analysis is performed on the software program, the static analysis using the first set of methods to determine a second set of methods having calling relationships with the selected source, the static analysis determining whether the returned value from the selected source can flow through a flow to a sink that performs a security-sensitive operation without the flow to the sink being endorsed, and in response, indicating a security violation. Apparatus and computer program products are also disclosed.
Incorporating Data Abstractions into Concurrency Control
Software applications are becoming increasingly harder to parallelize. Modern software systems written in imperative languages like Java and C# typically manipulate complex heap data structures, consist of multiple layers of abstraction, and have input- and deployment-specific behaviors that affect their available parallelism. This creates a significant challenge for parallelizing compilers, whose target transformations are normally conditioned on the assumption that the instructions designated for parallel execution access disjoint memory regions. Establishing this precondition over real-world applications is hard: Often there are dependencies between the candidate code blocks at the concrete level, at least over some of the inputs, and even if disjointness holds universally, it is hard for an automated verifier to formulate a proof to this effect. These limitations of dependence analysis in dealing with the complexity of modern programs, as well as their dynamic behavior, have shifted attention to runtime optimistic parallelization techniques, and most notably, software transactional memory (STM). The challenge with this approach is that STM typically incurs high overheaddue mainly to runtime tracking of memory accesses and conservative conflict detectionwhich often obviates the performance gain from parallelization. In this thesis, we take a step toward overcoming the limitations of these general parallelization techniques by taking benefit of user-provided data abstractions. These let us lift disjointness-driven parallelization to the level of semantic reasoning about data access and manipulation, enabling in turn nontrivial optimizations to the parallelization system. Specifically, we develop methods for abstract-level dynamic data dependence analysis, which serves us as the basis for specialized optimizations targeting prevalent program behaviors and common input profiles. We demonstrate the utility of our techniques with reference to realistic programs and popular parallelization techniques, e.g., by dramatically reducing the overhead of STM conflict detection
Verification of information-flow downgraders
A method includes determining grammar for output of an information-flow downgrader in a software program. The software program directs the output of the information-flow downgrader to a sink. The method includes determining whether the grammar of the output conforms to one or more predetermined specifications of the sink. The method includes, in response to a determination the grammar of the output conforms to the one or more predetermined specifications of the sink, determining the information-flow downgrader is verified for the sink, wherein determining grammar, determining whether the grammar, and determining the information-flow downgrader are performed via static analysis of the software program. Apparatus and computer program products are also disclosed. An apparatus includes a user interface providing a result of whether or not output of an information-flow downgrader in the software program conforms to one or more predetermined specifications of a sink in the software program.
Automatic inference of whitelist-based validation as part of static analysis for security
A method includes performing taint analysis of a computer program and determining an original set of paths from sources to sinks. Each path corresponds to a vulnerability. The method includes determining for each variable whose type is a collection and is accessed in one of the paths in the original set of paths whether the variable points to a concrete value whose internal state is not tainted according to the taint analysis. The method further includes, for each of the variables whose type is a collection found not to be tainted according to the taint analysis, determining all points in the computer program where a membership check against the collection is performed. The method also includes, for each of the points, determining corresponding paths and removing those paths from the original set of paths to create a reduced set of paths. Apparatus and computer readable program products are also disclosed.
Classification of code constructs using string analysis
A code construct in a computer-based software application is classified by seeding an analysis of an instruction code set of a computer-based software application with a seed for a seeding variable within the instruction code set, wherein the seed is an abstract value representation, performing the analysis to a fixed point, thereby producing a fixed point solution, selecting an invariant from the fixed point solution, wherein the invariant represents at least one value pointed to by a classification variable in a code construct within the instruction code set, and classifying the code construct with a classification that is applicable to the invariant in accordance with an application criterion.
Eliminating false reports of security vulnerabilities when testing computer software
A system for eliminating false reports of security vulnerabilities when testing computer software, including a taint analysis engine configured to identify a tainted variable v in a computer application, a data mapping identification engine configured to identify a variable x within the application that holds data derived from v, where x is in a different format than v, an AddData identification engine configured to identify an AddData operation within the application that is performed on x, a signature identification engine configured to identify a Sign operation within the application that is performed on the results of the AddData operation on x, a signature comparison identification engine configured to identify an operation within the application that compares the results of the Sign operation with another value.
Turning nondeterminism into parallelism
Nondeterminism is a useful and prevalent concept in the design and implementation of software systems. An important property of nondeterminism is its latent parallelism: A nondeterministic action can evaluate to multiple behaviors. If at least one of these behaviors does not conflict with concurrent tasks, then there is an admissible execution of the action in parallel with these tasks. Unfortunately, existing implementations of the atomic paradigm - optimistic as well as pessimistic - are unable to fully exhaust the parallelism potential of nondeterministic actions, lacking the means to guide concurrent tasks toward nondeterministic choices that minimize interference. This paper investigates the problem of utilizing parallelism due to nondeterminism. We observe that nondeterminism occurs in many real-world codes. We motivate the need for devising coordination mechanisms that can utilize available nondeterminism. We have developed a system featuring such mechanisms, which leverages nondeterminism in a wide class of query operations, allowing a task to look into the future of concurrent tasks that mutate the shared state during query evaluation and reduce conflict accordingly. We evaluate our system on a suite of 12 algorithmic benchmarks of wide applicability, as well as an industrial application. The results are encouraging.
Label-based taint analysis
A computer-implemented method and apparatus, adapted to receive a computer program, and dynamically analyze the computer program to determine flow of untrusted data with respect to a computer resource associated with the computer program. Based on the flow of untrusted data, the method and apparatus determine an abstraction of the computerized resource, and performing static analysis of the computer program with respect to the abstraction, wherein the static analysis is for identifying whether the computer program is susceptible to one or more possible security vulnerabilities.
System, method and apparatus for simultaneous definition and enforcement of access-control and integrity policies
Access-control and information-flow integrity policies are enforced in a computing system by detecting security-sensitive sinks in software code for an application running on the computing system and retrieving an access-control policy from a database accessible to the computing system. The access-control policy maps a set of access permissions within the computing system to each one of a plurality of principals. For each detected security-sensitive sink, all principals that influence that security-sensitive sink are detected and an overall access permission is assigned to each security-sensitive sink by taking the intersection of the access permission sets for all influencing principals of that security-sensitive sink. If this permission set is inadequate, an integrity violation is reported. In addition, permission labels are assigned to each value of variables used in the security-sensitive sinks. Each permission label is a set of permissions.
Policy-driven detection and verification of methods such as sanitizers and validators
A method includes performing a static analysis on a program having sources and sinks to track string flow from the sources to the sinks. The static analysis includes, for string variables in the program that begin at sources, computing grammar of all possible string values for each of the string variables and, for methods in the program operating on any of the string variables, computing grammar of string variables returned by the methods. The static analysis also includes, in response to one of the string variables reaching a sink that performs a security-sensitive operation, comparing current grammar of the one string variable with a policy corresponding to the security-sensitive operation, and performing a reporting operation based on the comparing. Apparatus and computer program products are also disclosed.
Path-and index-sensitive string analysis based on monadic second-order logic
We propose a novel technique for statically verifying the strings generated by a program. The verification is conducted by encoding the program in Monadic Second-order Logic (M2L). We use M2L to describe constraints among program variables and to abstract built-in string operations. Once we encode a program in M2L, a theorem prover for M2L, such as MONA, can automatically check if a string generated by the program satisfies a given specification, and if not, exhibit a counterexample. With this approach, we can naturally encode relationships among strings, accounting also for cases in which a program manipulates strings using indices. In addition, our string analysis is path sensitive in that it accounts for the effects of string and Boolean comparisons, as well as regular-expression matches. We have implemented our string analysis algorithm, and used it to augment an industrial security analysis for Web applications by automatically detecting and verifying sanitizersmethods that eliminate malicious patterns from untrusted strings, making these strings safe to use in security-sensitive operations. On the 8 benchmarks we analyzed, our string analyzer discovered 128 previously unknown sanitizers, compared to 71 sanitizers detected by a previously presented string analysis.
Enforcement of data privacy to maintain obfuscation of certain data
A computer-readable medium is disclosed that tangibly embodies a program of machine-readable instructions executable by a digital processing apparatus to perform operations including determining whether data to be released from a database is associated with one or more confidential mappings between sets of data in the database. The operations also include, in response to the data being associated with the one or more confidential mappings, determining whether release of the data meets one or more predetermined anonymity requirements of an anonymity policy. Methods and apparatus are also disclosed.
Identification of read/write chains during static analysis of computer software
A system for identifying read/write chains in computer software, including a static analysis engine identifying within computer software logical container accesses, a string analyzer configured to at least partly resolve any variables identifying the logical container in any of the accesses by determining a set of potential values of any of the variables, and a Logical Container Access Virtualization component (LCAV) configured to identify the type and scope of any permutations of the accesses, where each of the permutations is defined by substituting any of the potential values for any of the access variables, and identify any read/write chains within the computer software by matching any of the access permutations that read from the logical container with any of the access permutations that write to the logical container if there is an intersection between the scopes of the read and write access permutations.
Injection context based static analysis of computer software applications
Embodiments of the invention generally relate to injection context based static analysis of computer software applications. Embodiments of the invention may include selecting a sink within a computer software application, tracing a character output stream leading to the sink within the computer software application, determining an injection context of the character output stream at the sink, where the injection context is predefined in association with a state of the character output stream at the sink, identifying any actions that have been predefined in association with the identified injection context, and providing a report of the actions.
Partition-based static analysis of computer software applications
Partition-based static analysis of computer software applications may include inspecting each of a plurality of modules of a computer software application to identify at least one dependency of the inspected module on at least one other module of the computer software application, for each of the inspected modules, determining any transitive dependencies of the inspected module from the dependencies identified for the inspected module, performing a first static analysis on one of the inspected modules and its transitive dependencies, and performing a second static analysis on another of the inspected modules and its transitive dependencies, where the first and second analyses may be performed independently from each other.
Detecting and localizing security vulnerabilities in client-server application
The present invention provides a system, computer program product, and a computer implemented method for analyzing a set of two or more communicating applications. The method includes executing a first application, such as a client application, and executing a second application, such as a server application. The applications are communicating with each other. A correlation is recorded between the applications and an execution characteristic exhibited on execution. An oracle is used to determine an analysis of the first application that has been executed. The execution of the first application causes a change of state in the second application and/or a change control flow in the second application. Code fragment in the first application and/or the second application are prioritized based on an evaluation produced by the oracle, and based on the correlation between the code fragments that have been executed and the execution characteristic exhibited by the code fragments.
Tightfit: Adaptive parallelization with foresight
Irregular applications often exhibit data-dependent parallelism: Different inputs, and sometimes also different execution phases, enable different levels of parallelism. These changes in available parallelism have motivated work on adaptive concurrency control mechanisms. Existing adaptation techniques mostly learn about available parallelism indirectly, through runtime monitors that detect pathologies (e.g. excessive retries in speculation or high lock contention in mutual exclusion). We present a novel approach to adaptive parallelization, whereby the effective level of parallelism is predicted directly based on input features, rather than through circumstantial indicators over the execution environment (such as retry rate). This enables adaptation with foresight, based on the input data and not the run prefix. For this, the user specifies input features, which our system then correlates with the amount of available parallelism through offline learning. The resulting prediction rule serves in deployment runs to foresee the available parallelism for a given workload and tune the parallelization system accordingly. We have implemented our approach in TIGHTFIT, a general framework for input-centric offline adaptation. Our experimental evaluation of TIGHTFIT over two adaptive runtime systems and eight benchmarks provides positive evidence regarding TIGHTFIT's efficacy and accuracy.
Confidence-based static analysis
Systems, methods and program products are provided for confidence-based static analysis, including initiating a static analysis of computer software, associating a confidence value with a first element of the static analysis, determining a current state of the static analysis, calculating an adjusted confidence value in accordance with a confidence adjustment function as applied to the current state and the confidence value associated with the first element, associating the adjusted confidence value with a second element of the static analysis resulting from a transition from the first element, and eliminating the second element from the static analysis if the adjusted confidence value meets elimination criteria.
Finding your way in the testing jungle: a learning approach to web security testing
Black-box security testing of web applications is a hard problem. The main complication lies in the black-box assumption: The testing tool has limited insight into the workings of server-side defenses. This has traditionally led commercial as well as research vulnerability scanners toward heuristic approaches, such as testing each input point (e.g. HTTP parameter) with a short, predefined list of effective test payloads to balance between coverage and performance. We take a fresh approach to the problem of security testing, casting it into a learning setting. In our approach, the testing algorithm has available a comprehensive database of test payloads, such that if the web application's defenses are broken, then with near certainty one of the candidate payloads is able to demonstrate the vulnerability. The question then becomes how to efficiently search through the payload space to find a good candidate. In our solution, the learning algorithm infers from a failed test---by analyzing the website's response---which other payloads are also likely to fail, thereby pruning substantial portions of the search space. We have realized our approach in XSS Analyzer, an industry-level cross-site scripting (XSS) scanner featuring 500,000,000 test payloads. Our evaluation on 15,552 benchmarks shows solid results: XSS Analyzer achieves >99% coverage relative to brute-force traversal over all payloads, while trying only 10 payloads on average per input point. XSS Analyzer also outperforms several competing algorithms, including a mature commercial algorithm---featured in IBM Security AppScan Standard V8.5---by a far margin. XSS Analyzer has recently been integrated into the latest version of AppScan (V8.6) instead of that algorithm.
Scenario-based crawling
An interactive session can be established between a crawling bot and a Web site. The crawling bot can defines a session state representing a user state for interacting with one or more Web sites, a set of conditions, and a set of scenarios to be selectively activated based on whether the set of conditions are satisfied. The crawling bot can receive content from the Web site during the interactive session. The crawling bot can parse the content from the Web site and can matching the parsed content against a previously defined set of items to determine whether the content matching condition is satisfied. If the content matching condition is satisfied and if the state condition is satisfied, the crawling bot, activating of the scenarios defined by the crawling bot can be active, which is not activated if the content matching condition and the state condition are not satisfied.
Detection of second order vulnerabilities in web services
A system for detecting a vulnerability in a Web service can include a processor configured to initiate executable operations including determining whether a Web service uses identity of a requester to select one of a plurality of different paths of a branch in program code of the Web service and, responsive to determining that the Web service does select one of a plurality of different paths of a branch according to identity of the requester, indicating that the Web service has a potential vulnerability.
Detection of second order vulnerabilities in web services
A method of detecting a vulnerability in a Web service can include determining, using a processor, whether a Web service uses identity of a requester to select one of a plurality of different paths of a branch in program code of the Web service. The method further can include, responsive to determining that the Web service does select one of a plurality of different paths of a branch according to identity of the requester, indicating that the Web service has a potential vulnerability.
Identifying security vulnerability in computer software
Identifying a security vulnerability in a computer software application by identifying at least one source in a computer software application, identifying at least one sink in the computer software application, identifying at least one input to any of the sinks, determining whether the input derives its value directly or indirectly from any of the sources, determining a set of possible values for the input, and identifying a security vulnerability where the set of possible values for the input does not match a predefined specification of legal values associated with the sink input.
Optimizing automated interactions with computer software applications
Performing an automated interaction with a computer software application by identifying, among a plurality of regions of an interface of a computer software application, a region for which a region-level measure exists of user interaction that occurred within the region of the interface, determining if the region-level measure meets or exceeds a predefined minimum level of user interaction, and performing an automated interaction with an element at least partly found within the region if the region-level measure meets or exceeds the predefined minimum level of user interaction.
Static analysis with input reduction
Statically analyzing a computer software application can include identifying a plurality of objects within the instructions of a computer software application, where the objects in the plurality of objects are of the same object type, and preparing a modified version of the instructions in which any of the objects in the plurality of objects determined to be extraneous is omitted.
Andromeda: Accurate and scalable security analysis of web applications
Security auditing of industry-scale software systems mandates automation. Static taint analysis enables deep and exhaustive tracking of suspicious data flows for detection of potential leakage and integrity violations, such as cross-site scripting (XSS), SQL injection (SQLi) and log forging. Research in this area has taken two directions: program slicing and type systems. Both of these approaches suffer from a high rate of false findings, which limits the usability of analysis tools based on these techniques. Attempts to reduce the number of false findings have resulted in analyses that are either (i) unsound, suffering from the dual problem of false negatives, or (ii) too expensive due to their high precision, thereby failing to scale to real-world applications. In this paper, we investigate a novel approach for enabling precise yet scalable static taint analysis. The key observation informing our approach is that taint analysis is a demand-driven problem, which enables lazy computation of vulnerable information flows, instead of eagerly computing a complete data-flow solution, which is the reason for the traditional dichotomy between scalability and precision. We have implemented our approach in Andromeda, an analysis tool that computes data-flow propagations on demand, in an efficient and accurate manner, and additionally features incremental analysis capabilities. Andromeda is currently in use in a commercial product. It supports applications written in Java, .NET and JavaScript. Our extensive evaluation of Andromeda on a suite of 16 production-level benchmarks shows Andromeda to achieve high accuracy and compare favorably to a state-of-the-art tool that trades soundness for precision.
Detecting security vulnerabilities relating to cryptographically-sensitive information carriers when testing computer software
A system for detecting security vulnerabilities in computer software, including a cryptographic API identifier configured to identify a cryptographic API among the instructions of a computer software application, a path-to-source tracer configured to trace an information flow path among the instructions between the cryptographic API and a source that directly or indirectly provides data that are input to the cryptographic API, where a cryptographically-sensitive information carrier lies along the information flow path, a path-to-sink tracer configured to trace an information flow path among the instructions from the cryptographically-sensitive information carrier to a sink, and a security vulnerability identifier configured to provide a notification that the information flow path between the cryptographically-sensitive information carrier and the sink represents security vulnerability if the information flow path between the cryptographically-sensitive information carrier and the sink does not pass through a cryptographic API.
Black box testing optimization using information from white box testing
Testing a computer software application by identifying a sink in the computer software application, identifying a source associated with the sink in the application, identifying an entry point associated with the source in the application, where the source is configured to receive input provided externally to the application via the entry point, determining a sink type represented by the sink, and providing to a testing application information identifying the entry point and in association with the sink type.
Modular and/or demand-driven string analysis of a computer program
Modular and/or demand-driven string analysis of a computer program is performed. Each method of the program is encoded into monadic second-order logic (M2L) to yield a set of predicate declarations and a set of constraints. The two sets for each method are composed to yield a union set of predicate declarations and a union set of constraints for the program. The union set of constraints includes a particular set of constraints corresponding to call relationships among the methods. An M2L formula including a free variable corresponding to a program variable is added to the union set of constraints. The two union sets are processed to verify a satisfiability of the constraints in relation to an illegal pattern. Where the constraints are satisfiable, the program can generate a string containing the illegal pattern. Where the constraints are not satisfiable, the program never generates a string containing the illegal pattern.
Importance-based call graph construction
A system and method for importance-based call graph construction, including a) analyzing a computer software application to identify a plurality of calls within the computer software application, b) assigning an importance value to any of the calls in accordance with a predefined importance rule, c) selecting any of the calls for inclusion in a call graph in accordance with a predefined inclusion rule, d) representing the call in the call graph, e) adjusting the importance value of any call represented in the call graph in accordance with a predefined importance adjustment rule, and f) iteratively performing any of steps a)-e) until a predefined termination condition is met.
Determining whether method of computer program is a validator
An illegal pattern and a computer program having a method are received. The method has one or more return statements, and a number of basic blocks. The method is normalized so that each return statement of the target method relating to the illegal pattern returns a constant Boolean value. A first path condition and a second path condition for one or more corresponding paths is determined such that one or more corresponding basic blocks return a constant Boolean value of true for the first path condition and a constant Boolean value of false for the second path condition. An unsatisfiability of each path condition is determined using a monadic second-order logic (M2L) technique. Where the unsatisfiability of either path condition is false, the method is reported as not being a validator. Where the unsatisfiability of either path condition is true, the method is reported as being a validator.
Web crawling using static analysis
A crawler including a document retriever configured to retrieve a first computer-based document, a link identifier configured to identify an actual string within the computer-based document as being a hyperlink-type string, and a static analyzer configured to perform static analysis of an operation on a variable within the first computer-based document to identify a possible string value of the variable as being a hyperlink-type string, where any of the strings indicate a location of at least a second computer-based document.
JANUS: exploiting parallelism via hindsight
This paper addresses the problem of reducing unnecessary conflicts in optimistic synchronization. Optimistic synchronization must ensure that any two concurrently executing transactions that commit are properly synchronized. Conflict detection is an approximate check for this condition. For efficiency, the traditional approach to conflict detection conservatively checks that the memory locations mutually accessed by two concurrent transactions are accessed only for reading. We present JANUS, a parallelization system that performs conflict detection by considering sequences of operations and their composite effect on the system's state. This is done efficiently, such that the runtime overhead due to conflict detection is on a par with that of write-conflict-based detection. In certain common scenarios, this mode of refinement dramatically improves the precision of conflict detection, thereby reducing the number of false conflicts. Our empirical evaluation of JANUS shows that this precision gain reduces the abort rate by an order of magnitude (22x on average), and achieves a speedup of up to 2.5x, on a suite of real-world benchmarks where no parallelism is exploited by the standard approach.
Incremental static analysis
A system, method and computer program product for incremental static analysis, including a change impact analyzer for identifying a changed portion of a computer software (e.g., an application), where the changed portion was changed subsequent to performing a static analysis on the application, a static analysis result invalidator for invalidating any static analysis result that is dependent on the changed portion, and an incremental static analyzer for performing a first incremental static analysis on at least the changed portion, presenting the results of the first incremental static analysis, receiving a request to provide additional information regarding a selected result of the first incremental static analysis, performing, responsive to receiving the request, a second incremental static analysis on any portion of the application to gather the additional information, and presenting results of the second incremental static analysis, thereby providing the additional information regarding the selected result of the first incremental static analysis.
Hawkeye: effective discovery of dataflow impediments to parallelization
Parallelization transformations are an important vehicle for improving the performance and scalability of a software system. Utilizing concurrency requires that the developer first identify a suitable parallelization scope: one that poses as a performance bottleneck, and at the same time, exhibits considerable available parallelism. However, having identified a candidate scope, the developer still needs to ensure the correctness of the transformation. This is a difficult undertaking, where a major source of complication lies in tracking down sequential dependencies that inhibit parallelization and addressing them. We report on Hawkeye, a dynamic dependence-analysis tool that is designed to assist programmers in pinpointing such impediments to parallelization. In contrast with field-based dependence analyses, which track concrete memory conflicts and thus suffer from a high rate of false reports, Hawkeye tracks dependencies induced by the abstract semantics of the data type while ignoring dependencing arising solely from implementation artifacts. This enables a more concise report, where the reported dependencies are more likely to be real as well as intelligible to the programmer.
F4F: taint analysis of framework-based web applications
This paper presents F4F (Framework For Frameworks), a system for effective taint analysis of framework-based web applications. Most modern web applications utilize one or more web frameworks, which provide useful abstractions for common functionality. Due to extensive use of reflective language constructs in framework implementations, existing static taint analyses are often ineffective when applied to framework-based applications. While previous work has included ad hoc support for certain framework constructs, adding support for a large number of frameworks in this manner does not scale from an engineering standpoint. F4F employs an initial analysis pass in which both application code and configuration files are processed to generate a specification of framework-related behaviors. A taint analysis engine can leverage these specifications to perform a much deeper, more precise analysis of framework-based applications. Our specification language has only a small number of simple but powerful constructs, easing analysis engine integration. With this architecture, new frameworks can be handled with no changes to the core analysis engine, yielding significant engineering benefits. We implemented specification generators for several web frameworks and added F4F support to a state-of-the-art taint-analysis engine. In an experimental evaluation, the taint analysis enhanced with F4F discovered 525 new issues across nine benchmarks, a harmonic mean of 2.10X more issues per benchmark. Furthermore, manual inspection of a subset of the new issues showed that many were exploitable or reflected bad security practice.
Saving the world wide web from vulnerable JavaScript
JavaScript is the most popular client-side scripting language for Web applications. Exploitable JavaScript code exposes end users to integrity and confidentiality violations. Client-side vulnerabilities can cost an enterprise money and reputation, and cause serious damage to innocent users of the Web application. In spite of all this, recent research in the area of information-flow security has focused more on other languages that are more suitable for server-side programming, such as Java. Static analysis of JavaScript code is very challenging due to the dynamic nature of the language. This paper presents Actarus, a novel, product-quality static taint analysis for JavaScript that scales to large programs and soundly models all the JavaScript constructs with the exception of reflective calls. This paper discusses the experimental results obtained by running Actarus on a collection of 9,726 Web pages obtained by crawling the 50 most visited Web sites worldwide as well as 19 other popular Web sites. The results expose 526 vulnerabilities in 11 sites. Those vulnerabilities, if exploited, can allow malicious JavaScript code execution.
Learning minimal abstractions
Static analyses are generally parametrized by an abstraction which is chosen from a family of abstractions. We are interested in flexible families of abstractions with many parameters, as these families can allow one to increase precision in ways tailored to the client without sacrificing scalability. For example, we consider k-limited points-to analyses where each call site and allocation site in a program can have a different k value. We then ask a natural question in this paper: What is the minimal (coarsest) abstraction in a given family which is able to prove a set of queries? In addressing this question, we make the following two contributions: (i) We introduce two machine learning algorithms for efficiently finding a minimal abstraction; and (ii) for a static race detector backed by a k-limited points-to analysis, we show empirically that minimal abstractions are actually quite coarse: It suffices to provide context/object sensitivity to a very small fraction (0.4-2.3%) of the sites to yield equally precise results as providing context/object sensitivity uniformly to all sites.
Hybrid analysis for JavaScript security assessment
With the proliferation of Web 2.0 technologies, functionality in web applications is increasingly moving from server-side to client-side code, primarily JavaScript. The dynamic and eventdriven nature of JavaScript code, which is often machine generated or obfuscated, combined with reliance on complex frameworks and asynchronous communication, makes it difficult to perform effective security auditing of client-side JavaScript using existing static- and dynamic-analysis techniques. We present a commercial-grade hybrid-analysis solution for automated security assessment of client-side JavaScript code. Our approach brings together the advantages of the white-box and black-box methodologies while overcoming their weaknesses. A black-box component interacts with the subject web application and collects pages that contain client-side JavaScript code. The pages are then analyzed using static taint analysis to detect security vulnerabilities. The black-box component provides URLs and other pieces of dynamic information that contribute toward specializing the static analysis, making it much more precise and effective than its baseline version, as we demonstrate empirically.
A dynamic evaluation of the precision of static heap abstractions
The quality of a static analysis of heap-manipulating programs is largely determined by its heap abstraction. Object allocation sites are a commonly-used abstraction, but are too coarse for some clients. The goal of this paper is to investigate how various refinements of allocation sites can improve precision. In particular, we consider abstractions that use call stack, object recency, and heap connectivity information. We measure the precision of these abstractions dynamically for four different clients motivated by concurrency and on nine Java programs chosen from the DaCapo benchmark suite. Our dynamic results shed new light on aspects of heap abstractions that matter for precision, which allows us to more effectively navigate the large space of possible heap abstractions
TAJ: effective taint analysis of web applications
Taint analysis, a form of information-flow analysis, establishes whether values from untrusted methods and parameters may flow into security-sensitive operations. Taint analysis can detect many common vulnerabilities in Web applications, and so has attracted much attention from both the research community and industry. However, most static taint-analysis tools do not address critical requirements for an industrial-strength tool. Specifically, an industrial-strength tool must scale to large industrial Web applications, model essential Web-application code artifacts, and generate consumable reports for a wide range of attack vectors. We have designed and implemented a static Taint Analysis for Java (TAJ) that meets the requirements of industry-level applications. TAJ can analyze applications of virtually any size, as it employs a set of techniques designed to produce useful answers given limited time and space. TAJ addresses a wide variety of attack vectors, with techniques to handle reflective calls, flow through containers, nested taint, and issues in generating useful reports. This paper provides a description of the algorithms comprising TAJ, evaluates TAJ against production-level benchmarks, and compares it with alternative solutions.
Exploration in the Dark: Reasoning about Planning Strategies
We present a new approach to reasoning about planning strategies in multiagent domains: an agent learns a boundedly-optimal planning strategy, relative to the current state of the environment and its goals, using a myopic attitude based on its repertoire of planning policies. In self-play, our approach also allows boundedly-optimal coordination. In terms of the exploration-exploitation tradeoff, the agent need not generate a model of its environment (nor of other domain agents) as part of its exploratory activities, which allows efficient exploration as well as tractability in real-world scenarios. As complement to the above approach, we present the Leap-and-Stride strategy, a novel probabilistic strategy that serves agents in situations where they can make no assumptions about their surroundings, either due to the lack of a priori knowledge about the environment, or because its complex and dynamic nature renders it inherently unpredictable. The Leap-and-Stride strategy interleaves exploratory activities into the agents planning logic, which enables it to converge to effective modes of interaction with its environment through trial-and-error. This strategy is tunable in the sense that the agent can control the intensity of its exploratory activities according to a risk management policy. We present theoretical results regarding the complexity of Leap-and-Stride, and demonstrate its viability through two sets of empirical studies.
